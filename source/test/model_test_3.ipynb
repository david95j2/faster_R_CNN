{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as FT\n",
    "from torchvision import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchsummary import summary\n",
    "import xml.etree.ElementTree as Et\n",
    "from typing import Any, Callable, Dict, Optional, Tuple, List\n",
    "import collections\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import imgaug as ia  # imgaug\n",
    "from imgaug import augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir(\"../../../../../../data/test/Annotations\")))\n",
    "print(len(os.listdir(\"../../../../../../data/test/JPEGImages\")))\n",
    "\n",
    "\n",
    "path = \"../../../../../../data/train/JPEGImages/WN4_142.jpg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_parser(xml_path):\n",
    "  xml_path = xml_path\n",
    "  xml = open(xml_path, \"r\")\n",
    "  tree = Et.parse(xml)\n",
    "  root = tree.getroot()\n",
    "  size = root.find(\"size\")\n",
    "  file_name = root.find(\"filename\").text\n",
    "  object_name = []\n",
    "  bbox = []\n",
    "  objects = root.findall(\"object\")\n",
    "  for _object in objects:\n",
    "      name = _object.find(\"name\").text\n",
    "      object_name.append(name)\n",
    "      bndbox = _object.find(\"bndbox\")\n",
    "      one_bbox = []\n",
    "      xmin = bndbox.find(\"xmin\").text\n",
    "      one_bbox.append(int(float(xmin)))\n",
    "      ymin = bndbox.find(\"ymin\").text\n",
    "      one_bbox.append(int(float(ymin)))\n",
    "      xmax = bndbox.find(\"xmax\").text\n",
    "      one_bbox.append(int(float(xmax)))\n",
    "      ymax = bndbox.find(\"ymax\").text\n",
    "      one_bbox.append(int(float(ymax)))\n",
    "      bbox.append(one_bbox)\n",
    "  return file_name, object_name, bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeBox(voc_im,bbox,objects):\n",
    "  image = voc_im.copy()\n",
    "  for i in range(len(objects)):\n",
    "    cv2.rectangle(image,(int(bbox[i][0]),int(bbox[i][1])),(int(bbox[i][2]),int(bbox[i][3])),color = (0,255,0),thickness = 1)\n",
    "    cv2.putText(image, objects[i], (int(bbox[i][0]), int(bbox[i][1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2) # 크기, 색, 굵기\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aeroplane': 1, 'bicycle': 2, 'bird': 3, 'boat': 4, 'bottle': 5, 'bus': 6, 'car': 7, 'cat': 8, 'chair': 9, 'cow': 10, 'diningtable': 11, 'dog': 12, 'horse': 13, 'motorbike': 14, 'person': 15, 'pottedplant': 16, 'sheep': 17, 'sofa': 18, 'train': 19, 'tvmonitor': 20}\n"
     ]
    }
   ],
   "source": [
    "xml_list = os.listdir(\"VOCdevkit/VOC2012/Annotations\")\n",
    "xml_list.sort()\n",
    "\n",
    "label_set = set()\n",
    "\n",
    "for i in range(len(xml_list)):\n",
    "  xml_path = \"VOCdevkit/VOC2012/Annotations/\"+str(xml_list[i])\n",
    "  file_name, object_name, bbox = xml_parser(xml_path)\n",
    "  for name in object_name:\n",
    "    label_set.add(name)\n",
    "\n",
    "label_set = sorted(list(label_set))\n",
    "\n",
    "label_dic = {}\n",
    "for i, key in enumerate(label_set):\n",
    "  label_dic[key] = (i+1)\n",
    "print(label_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pascal_Voc(Dataset):\n",
    "    \n",
    "  def __init__(self,xml_list,len_data):\n",
    "\n",
    "    self.xml_list = xml_list\n",
    "    self.len_data = len_data\n",
    "    self.to_tensor = transforms.ToTensor()\n",
    "    self.flip = iaa.Fliplr(0.5)\n",
    "    self.resize = iaa.Resize({\"shorter-side\": 600, \"longer-side\": \"keep-aspect-ratio\"})\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.len_data\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "\n",
    "    xml_path = \"VOCdevkit/VOC2012/Annotations/\"+str(xml_list[idx])\n",
    "\n",
    "    file_name, object_name, bbox = xml_parser(xml_path)\n",
    "    image_path = \"VOCdevkit/VOC2012/JPEGImages/\"+str(file_name)\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = np.array(image)\n",
    "\n",
    "    image, bbox = self.flip(image = image, bounding_boxes = np.array([bbox]))\n",
    "    image, bbox = self.resize(image = image,bounding_boxes = bbox)\n",
    "    bbox = bbox.squeeze(0).tolist()\n",
    "    image = self.to_tensor(image)\n",
    "\n",
    "    targets = []\n",
    "    d = {}\n",
    "    d['boxes'] = torch.tensor(bbox,device=device)\n",
    "    d['labels'] = torch.tensor([label_dic[x] for x in object_name],dtype=torch.int64,device = device)\n",
    "    targets.append(d)\n",
    "\n",
    "    return image, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = torchvision.models.vgg16(pretrained=True).features[:-1]\n",
    "backbone_out = 512\n",
    "backbone.out_channels = backbone_out\n",
    "\n",
    "anchor_generator = torchvision.models.detection.rpn.AnchorGenerator(\n",
    "    sizes=((128, 256, 512),), aspect_ratios=((0.5, 1.0, 2.0),))\n",
    "\n",
    "resolution = 7\n",
    "roi_pooler = torchvision.ops.MultiScaleRoIAlign(\n",
    "    featmap_names=['0'], output_size=resolution, sampling_ratio=2)\n",
    "\n",
    "box_head = torchvision.models.detection.faster_rcnn.TwoMLPHead(\n",
    "    in_channels=backbone_out*(resolution**2), representation_size=4096)\n",
    "box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(\n",
    "    4096, 21)  # 21개 class\n",
    "\n",
    "model = torchvision.models.detection.FasterRCNN(backbone, num_classes=None,\n",
    "                                                min_size=600, max_size=1000,\n",
    "                                                rpn_anchor_generator=anchor_generator,\n",
    "                                                rpn_pre_nms_top_n_train=6000, rpn_pre_nms_top_n_test=6000,\n",
    "                                                rpn_post_nms_top_n_train=2000, rpn_post_nms_top_n_test=300,\n",
    "                                                rpn_nms_thresh=0.7, rpn_fg_iou_thresh=0.7,  rpn_bg_iou_thresh=0.3,\n",
    "                                                rpn_batch_size_per_image=256, rpn_positive_fraction=0.5,\n",
    "                                                box_roi_pool=roi_pooler, box_head=box_head, box_predictor=box_predictor,\n",
    "                                                box_score_thresh=0.05, box_nms_thresh=0.7, box_detections_per_img=300,\n",
    "                                                box_fg_iou_thresh=0.5, box_bg_iou_thresh=0.5,\n",
    "                                                box_batch_size_per_image=128, box_positive_fraction=0.25\n",
    "                                                )\n",
    "#roi head 있으면 num_class = None으로 함\n",
    "\n",
    "for param in model.rpn.parameters():\n",
    "  torch.nn.init.normal_(param, mean=0.0, std=0.01)\n",
    "\n",
    "for name, param in model.roi_heads.named_parameters():\n",
    "  if \"bbox_pred\" in name:\n",
    "    torch.nn.init.normal_(param, mean=0.0, std=0.001)\n",
    "  elif \"weight\" in name:\n",
    "    torch.nn.init.normal_(param, mean=0.0, std=0.01)\n",
    "  if \"bias\" in name:\n",
    "    torch.nn.init.zeros_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-11 19:19:39.808426: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/joo/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda-10.2/lib64\n",
      "2022-02-11 19:19:39.808444: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-aa1a2d68e10fe68c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-aa1a2d68e10fe68c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "writer = SummaryWriter(\"runs/Faster_RCNN\")\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=\"runs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Total_Loss(loss):\n",
    "  loss_objectness = loss['loss_objectness']\n",
    "  loss_rpn_box_reg = loss['loss_rpn_box_reg']\n",
    "  loss_classifier = loss['loss_classifier']\n",
    "  loss_box_reg = loss['loss_box_reg']\n",
    "\n",
    "  rpn_total = loss_objectness + 10*loss_rpn_box_reg\n",
    "  fast_rcnn_total = loss_classifier + 1*loss_box_reg\n",
    "\n",
    "  total_loss = rpn_total + fast_rcnn_total\n",
    "\n",
    "  return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_epoch = 0 , start_idx = 6000\n",
      "Training Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joo/anaconda3/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180549130/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Iter 7000 | Loss: 2.4794702529907227 | Duration: 2 min\n",
      "Epoch 0 | Iter 8000 | Loss: 2.569445848464966 | Duration: 2 min\n",
      "Epoch 0 | Iter 9000 | Loss: 2.4855403900146484 | Duration: 2 min\n",
      "Epoch 0 | Iter 10000 | Loss: 2.4337081909179688 | Duration: 2 min\n",
      "Epoch 0 | Iter 11000 | Loss: 2.403154134750366 | Duration: 2 min\n",
      "Epoch 0 | Iter 12000 | Loss: 2.318570375442505 | Duration: 2 min\n",
      "Epoch 0 | Iter 13000 | Loss: 2.367945909500122 | Duration: 2 min\n",
      "Epoch 0 | Iter 14000 | Loss: 2.4955968856811523 | Duration: 2 min\n",
      "Epoch 0 | Iter 15000 | Loss: 2.357517957687378 | Duration: 2 min\n",
      "Epoch 1 | Iter 1000 | Loss: 2.110621452331543 | Duration: 2 min\n",
      "Epoch 1 | Iter 2000 | Loss: 2.2536275386810303 | Duration: 2 min\n",
      "Epoch 1 | Iter 3000 | Loss: 2.0594537258148193 | Duration: 2 min\n",
      "Epoch 1 | Iter 4000 | Loss: 2.139148473739624 | Duration: 2 min\n",
      "Epoch 1 | Iter 5000 | Loss: 2.1133790016174316 | Duration: 2 min\n",
      "Epoch 1 | Iter 6000 | Loss: 2.028985023498535 | Duration: 2 min\n",
      "Epoch 1 | Iter 7000 | Loss: 2.0904035568237305 | Duration: 2 min\n",
      "Epoch 1 | Iter 8000 | Loss: 2.0086331367492676 | Duration: 2 min\n",
      "Epoch 1 | Iter 9000 | Loss: 2.1200015544891357 | Duration: 2 min\n",
      "Epoch 1 | Iter 10000 | Loss: 1.9975852966308594 | Duration: 2 min\n",
      "Epoch 1 | Iter 11000 | Loss: 2.0511367321014404 | Duration: 2 min\n",
      "Epoch 1 | Iter 12000 | Loss: 2.052353620529175 | Duration: 2 min\n",
      "Epoch 1 | Iter 13000 | Loss: 2.0812559127807617 | Duration: 2 min\n",
      "Epoch 1 | Iter 14000 | Loss: 2.0675742626190186 | Duration: 2 min\n",
      "Epoch 1 | Iter 15000 | Loss: 1.9626137018203735 | Duration: 2 min\n",
      "Epoch 2 | Iter 1000 | Loss: 2.0816001892089844 | Duration: 2 min\n",
      "Epoch 2 | Iter 2000 | Loss: 1.9725635051727295 | Duration: 2 min\n",
      "Epoch 2 | Iter 3000 | Loss: 1.8730401992797852 | Duration: 2 min\n",
      "Epoch 2 | Iter 4000 | Loss: 2.0331456661224365 | Duration: 2 min\n",
      "Epoch 2 | Iter 5000 | Loss: 1.910707712173462 | Duration: 2 min\n",
      "Epoch 2 | Iter 6000 | Loss: 1.9704370498657227 | Duration: 2 min\n",
      "Epoch 2 | Iter 7000 | Loss: 1.9783101081848145 | Duration: 2 min\n",
      "Epoch 2 | Iter 8000 | Loss: 1.897111415863037 | Duration: 2 min\n",
      "Epoch 2 | Iter 9000 | Loss: 1.961825966835022 | Duration: 2 min\n",
      "Epoch 2 | Iter 10000 | Loss: 2.084122896194458 | Duration: 2 min\n",
      "Epoch 2 | Iter 11000 | Loss: 2.0878124237060547 | Duration: 2 min\n",
      "Epoch 2 | Iter 12000 | Loss: 1.9363839626312256 | Duration: 2 min\n",
      "Epoch 2 | Iter 13000 | Loss: 1.9346530437469482 | Duration: 2 min\n",
      "Epoch 2 | Iter 14000 | Loss: 1.9449669122695923 | Duration: 1 min\n",
      "Epoch 2 | Iter 15000 | Loss: 1.9496690034866333 | Duration: 2 min\n",
      "Epoch 3 | Iter 1000 | Loss: 1.877821922302246 | Duration: 2 min\n",
      "Epoch 3 | Iter 2000 | Loss: 2.0778567790985107 | Duration: 1 min\n",
      "Epoch 3 | Iter 3000 | Loss: 1.8494021892547607 | Duration: 2 min\n",
      "Epoch 3 | Iter 4000 | Loss: 2.0407493114471436 | Duration: 2 min\n",
      "Epoch 3 | Iter 5000 | Loss: 1.883571743965149 | Duration: 2 min\n",
      "Epoch 3 | Iter 6000 | Loss: 1.9662503004074097 | Duration: 2 min\n",
      "Epoch 3 | Iter 7000 | Loss: 1.8634898662567139 | Duration: 2 min\n",
      "Epoch 3 | Iter 8000 | Loss: 1.922174334526062 | Duration: 2 min\n",
      "Epoch 3 | Iter 9000 | Loss: 1.933053970336914 | Duration: 2 min\n",
      "Epoch 3 | Iter 10000 | Loss: 1.8524655103683472 | Duration: 2 min\n",
      "Epoch 3 | Iter 11000 | Loss: 1.8841689825057983 | Duration: 2 min\n",
      "Epoch 3 | Iter 12000 | Loss: 1.8445395231246948 | Duration: 2 min\n",
      "Epoch 3 | Iter 13000 | Loss: 1.933274269104004 | Duration: 2 min\n",
      "Epoch 3 | Iter 14000 | Loss: 1.8687431812286377 | Duration: 2 min\n",
      "Epoch 3 | Iter 15000 | Loss: 1.8432366847991943 | Duration: 2 min\n",
      "Epoch 4 | Iter 1000 | Loss: 1.753212332725525 | Duration: 2 min\n",
      "Epoch 4 | Iter 2000 | Loss: 1.8509973287582397 | Duration: 2 min\n",
      "Epoch 4 | Iter 3000 | Loss: 1.8314281702041626 | Duration: 2 min\n",
      "Epoch 4 | Iter 4000 | Loss: 1.8464008569717407 | Duration: 2 min\n",
      "Epoch 4 | Iter 5000 | Loss: 1.8202213048934937 | Duration: 2 min\n",
      "Epoch 4 | Iter 6000 | Loss: 1.7761549949645996 | Duration: 2 min\n",
      "Epoch 4 | Iter 7000 | Loss: 1.9468848705291748 | Duration: 2 min\n",
      "Epoch 4 | Iter 8000 | Loss: 1.9106281995773315 | Duration: 2 min\n",
      "Epoch 4 | Iter 9000 | Loss: 1.8120884895324707 | Duration: 2 min\n",
      "Epoch 4 | Iter 10000 | Loss: 1.8251376152038574 | Duration: 2 min\n",
      "Epoch 4 | Iter 11000 | Loss: 1.8604530096054077 | Duration: 2 min\n",
      "Epoch 4 | Iter 12000 | Loss: 1.9183223247528076 | Duration: 2 min\n",
      "Epoch 4 | Iter 13000 | Loss: 1.9337470531463623 | Duration: 2 min\n",
      "Epoch 4 | Iter 14000 | Loss: 1.8551924228668213 | Duration: 2 min\n",
      "Epoch 4 | Iter 15000 | Loss: 1.9128241539001465 | Duration: 2 min\n",
      "Epoch 5 | Iter 1000 | Loss: 1.8777775764465332 | Duration: 2 min\n",
      "Epoch 5 | Iter 2000 | Loss: 1.7439876794815063 | Duration: 2 min\n",
      "Epoch 5 | Iter 3000 | Loss: 1.8105320930480957 | Duration: 2 min\n",
      "Epoch 5 | Iter 4000 | Loss: 1.8291468620300293 | Duration: 2 min\n",
      "Epoch 5 | Iter 5000 | Loss: 1.8030072450637817 | Duration: 2 min\n",
      "Epoch 5 | Iter 6000 | Loss: 1.8452560901641846 | Duration: 2 min\n",
      "Epoch 5 | Iter 7000 | Loss: 1.7854503393173218 | Duration: 2 min\n",
      "Epoch 5 | Iter 8000 | Loss: 1.8199008703231812 | Duration: 2 min\n",
      "Epoch 5 | Iter 9000 | Loss: 1.7939084768295288 | Duration: 2 min\n",
      "Epoch 5 | Iter 10000 | Loss: 1.9002124071121216 | Duration: 2 min\n",
      "Epoch 5 | Iter 11000 | Loss: 1.8435032367706299 | Duration: 2 min\n",
      "Epoch 5 | Iter 12000 | Loss: 1.757041335105896 | Duration: 2 min\n",
      "Epoch 5 | Iter 13000 | Loss: 1.7449716329574585 | Duration: 2 min\n",
      "Epoch 5 | Iter 14000 | Loss: 1.9492244720458984 | Duration: 2 min\n",
      "Epoch 5 | Iter 15000 | Loss: 1.7945226430892944 | Duration: 2 min\n",
      "Epoch 6 | Iter 1000 | Loss: 1.7938165664672852 | Duration: 2 min\n",
      "Epoch 6 | Iter 2000 | Loss: 1.7153116464614868 | Duration: 2 min\n",
      "Epoch 6 | Iter 3000 | Loss: 1.8431133031845093 | Duration: 2 min\n",
      "Epoch 6 | Iter 4000 | Loss: 1.8157765865325928 | Duration: 2 min\n",
      "Epoch 6 | Iter 5000 | Loss: 1.7855889797210693 | Duration: 2 min\n",
      "Epoch 6 | Iter 6000 | Loss: 1.6951813697814941 | Duration: 2 min\n",
      "Epoch 6 | Iter 7000 | Loss: 1.697809100151062 | Duration: 2 min\n",
      "Epoch 6 | Iter 8000 | Loss: 1.8420161008834839 | Duration: 2 min\n",
      "Epoch 6 | Iter 9000 | Loss: 1.7324974536895752 | Duration: 2 min\n",
      "Epoch 6 | Iter 10000 | Loss: 1.7732057571411133 | Duration: 2 min\n",
      "Epoch 6 | Iter 11000 | Loss: 1.7567453384399414 | Duration: 2 min\n",
      "Epoch 6 | Iter 12000 | Loss: 1.8392869234085083 | Duration: 2 min\n",
      "Epoch 6 | Iter 13000 | Loss: 1.838070273399353 | Duration: 2 min\n",
      "Epoch 6 | Iter 14000 | Loss: 1.8747278451919556 | Duration: 2 min\n",
      "Epoch 6 | Iter 15000 | Loss: 1.7865129709243774 | Duration: 2 min\n",
      "Epoch 7 | Iter 1000 | Loss: 1.7652322053909302 | Duration: 2 min\n",
      "Epoch 7 | Iter 2000 | Loss: 1.6961143016815186 | Duration: 2 min\n",
      "Epoch 7 | Iter 3000 | Loss: 1.7590916156768799 | Duration: 2 min\n",
      "Epoch 7 | Iter 4000 | Loss: 1.6632745265960693 | Duration: 2 min\n",
      "Epoch 7 | Iter 5000 | Loss: 1.6227798461914062 | Duration: 2 min\n",
      "Epoch 7 | Iter 6000 | Loss: 1.7196911573410034 | Duration: 2 min\n",
      "Epoch 7 | Iter 7000 | Loss: 1.8118748664855957 | Duration: 2 min\n",
      "Epoch 7 | Iter 8000 | Loss: 1.768295168876648 | Duration: 2 min\n",
      "Epoch 7 | Iter 9000 | Loss: 1.7255520820617676 | Duration: 2 min\n",
      "Epoch 7 | Iter 10000 | Loss: 1.8029284477233887 | Duration: 2 min\n",
      "Epoch 7 | Iter 11000 | Loss: 1.7204493284225464 | Duration: 2 min\n",
      "Epoch 7 | Iter 12000 | Loss: 1.7106690406799316 | Duration: 2 min\n",
      "Epoch 7 | Iter 13000 | Loss: 1.8329987525939941 | Duration: 2 min\n",
      "Epoch 7 | Iter 14000 | Loss: 1.844547152519226 | Duration: 2 min\n",
      "Epoch 7 | Iter 15000 | Loss: 1.8103652000427246 | Duration: 2 min\n",
      "Epoch 8 | Iter 1000 | Loss: 1.6876745223999023 | Duration: 2 min\n",
      "Epoch 8 | Iter 2000 | Loss: 1.663378119468689 | Duration: 2 min\n",
      "Epoch 8 | Iter 3000 | Loss: 1.683609962463379 | Duration: 2 min\n",
      "Epoch 8 | Iter 4000 | Loss: 1.7819634675979614 | Duration: 2 min\n",
      "Epoch 8 | Iter 5000 | Loss: 1.7005500793457031 | Duration: 2 min\n",
      "Epoch 8 | Iter 6000 | Loss: 1.7655553817749023 | Duration: 2 min\n",
      "Epoch 8 | Iter 7000 | Loss: 1.6721702814102173 | Duration: 2 min\n",
      "Epoch 8 | Iter 8000 | Loss: 1.7397979497909546 | Duration: 2 min\n",
      "Epoch 8 | Iter 9000 | Loss: 1.6828354597091675 | Duration: 2 min\n",
      "Epoch 8 | Iter 10000 | Loss: 1.7498983144760132 | Duration: 2 min\n",
      "Epoch 8 | Iter 11000 | Loss: 1.7426916360855103 | Duration: 2 min\n",
      "Epoch 8 | Iter 12000 | Loss: 1.727043628692627 | Duration: 2 min\n",
      "Epoch 8 | Iter 13000 | Loss: 1.7743545770645142 | Duration: 2 min\n",
      "Epoch 8 | Iter 14000 | Loss: 1.6397390365600586 | Duration: 2 min\n",
      "Epoch 8 | Iter 15000 | Loss: 1.7037194967269897 | Duration: 2 min\n",
      "Epoch 9 | Iter 1000 | Loss: 1.6627823114395142 | Duration: 2 min\n",
      "Epoch 9 | Iter 2000 | Loss: 1.663271427154541 | Duration: 2 min\n",
      "Epoch 9 | Iter 3000 | Loss: 1.6489970684051514 | Duration: 2 min\n",
      "Epoch 9 | Iter 4000 | Loss: 1.7832945585250854 | Duration: 2 min\n",
      "Epoch 9 | Iter 5000 | Loss: 1.7297837734222412 | Duration: 2 min\n",
      "Epoch 9 | Iter 6000 | Loss: 1.6775544881820679 | Duration: 2 min\n",
      "Epoch 9 | Iter 7000 | Loss: 1.5954155921936035 | Duration: 2 min\n",
      "Epoch 9 | Iter 8000 | Loss: 1.6374797821044922 | Duration: 2 min\n",
      "Epoch 9 | Iter 9000 | Loss: 1.6825157403945923 | Duration: 2 min\n",
      "Epoch 9 | Iter 10000 | Loss: 1.6892626285552979 | Duration: 2 min\n",
      "Epoch 9 | Iter 11000 | Loss: 1.6872483491897583 | Duration: 2 min\n",
      "Epoch 9 | Iter 12000 | Loss: 1.808014988899231 | Duration: 2 min\n",
      "Epoch 9 | Iter 13000 | Loss: 1.6653087139129639 | Duration: 2 min\n",
      "Epoch 9 | Iter 14000 | Loss: 1.728087067604065 | Duration: 2 min\n",
      "Epoch 9 | Iter 15000 | Loss: 1.6877985000610352 | Duration: 2 min\n",
      "Epoch 10 | Iter 1000 | Loss: 1.6432886123657227 | Duration: 2 min\n",
      "Epoch 10 | Iter 2000 | Loss: 1.636356234550476 | Duration: 2 min\n",
      "Epoch 10 | Iter 3000 | Loss: 1.7712938785552979 | Duration: 2 min\n",
      "Epoch 10 | Iter 4000 | Loss: 1.7017663717269897 | Duration: 2 min\n",
      "Epoch 10 | Iter 5000 | Loss: 1.5540673732757568 | Duration: 2 min\n",
      "Epoch 10 | Iter 6000 | Loss: 1.6118568181991577 | Duration: 2 min\n",
      "Epoch 10 | Iter 7000 | Loss: 1.6847450733184814 | Duration: 2 min\n",
      "Epoch 10 | Iter 8000 | Loss: 1.608453392982483 | Duration: 2 min\n",
      "Epoch 10 | Iter 9000 | Loss: 1.64840829372406 | Duration: 2 min\n",
      "Epoch 10 | Iter 10000 | Loss: 1.647855281829834 | Duration: 2 min\n",
      "Epoch 10 | Iter 11000 | Loss: 1.672682762145996 | Duration: 2 min\n",
      "Epoch 10 | Iter 12000 | Loss: 1.604803204536438 | Duration: 2 min\n",
      "Epoch 10 | Iter 13000 | Loss: 1.631089448928833 | Duration: 2 min\n",
      "Epoch 10 | Iter 14000 | Loss: 1.7365282773971558 | Duration: 2 min\n",
      "Epoch 10 | Iter 15000 | Loss: 1.7278066873550415 | Duration: 2 min\n",
      "Epoch 11 | Iter 1000 | Loss: 1.6593085527420044 | Duration: 2 min\n",
      "Epoch 11 | Iter 2000 | Loss: 1.595568060874939 | Duration: 2 min\n",
      "Epoch 11 | Iter 3000 | Loss: 1.6347373723983765 | Duration: 2 min\n",
      "Epoch 11 | Iter 4000 | Loss: 1.5627942085266113 | Duration: 2 min\n",
      "Epoch 11 | Iter 5000 | Loss: 1.6365104913711548 | Duration: 2 min\n",
      "Epoch 11 | Iter 6000 | Loss: 1.5464189052581787 | Duration: 2 min\n",
      "Epoch 11 | Iter 7000 | Loss: 1.5787279605865479 | Duration: 2 min\n",
      "Epoch 11 | Iter 8000 | Loss: 1.5537943840026855 | Duration: 2 min\n",
      "Epoch 11 | Iter 9000 | Loss: 1.6203327178955078 | Duration: 2 min\n",
      "Epoch 11 | Iter 10000 | Loss: 1.6711941957473755 | Duration: 2 min\n",
      "Epoch 11 | Iter 11000 | Loss: 1.552736520767212 | Duration: 2 min\n",
      "Epoch 11 | Iter 12000 | Loss: 1.6976556777954102 | Duration: 2 min\n",
      "Epoch 11 | Iter 13000 | Loss: 1.6824548244476318 | Duration: 2 min\n",
      "Epoch 11 | Iter 14000 | Loss: 1.6703057289123535 | Duration: 2 min\n",
      "Epoch 11 | Iter 15000 | Loss: 1.7181943655014038 | Duration: 2 min\n",
      "Epoch 12 | Iter 1000 | Loss: 1.535006046295166 | Duration: 2 min\n",
      "Epoch 12 | Iter 2000 | Loss: 1.5502259731292725 | Duration: 2 min\n",
      "Epoch 12 | Iter 3000 | Loss: 1.529729962348938 | Duration: 2 min\n",
      "Epoch 12 | Iter 4000 | Loss: 1.6812669038772583 | Duration: 2 min\n",
      "Epoch 12 | Iter 5000 | Loss: 1.5631465911865234 | Duration: 2 min\n",
      "Epoch 12 | Iter 6000 | Loss: 1.4890812635421753 | Duration: 2 min\n",
      "Epoch 12 | Iter 7000 | Loss: 1.5768710374832153 | Duration: 2 min\n",
      "Epoch 12 | Iter 8000 | Loss: 1.609257698059082 | Duration: 2 min\n",
      "Epoch 12 | Iter 9000 | Loss: 1.6165751218795776 | Duration: 2 min\n",
      "Epoch 12 | Iter 10000 | Loss: 1.6257535219192505 | Duration: 2 min\n",
      "Epoch 12 | Iter 11000 | Loss: 1.5929052829742432 | Duration: 2 min\n",
      "Epoch 12 | Iter 12000 | Loss: 1.6296038627624512 | Duration: 2 min\n",
      "Epoch 12 | Iter 13000 | Loss: 1.6180267333984375 | Duration: 2 min\n",
      "Epoch 12 | Iter 14000 | Loss: 1.6349221467971802 | Duration: 2 min\n",
      "Epoch 12 | Iter 15000 | Loss: 1.5517759323120117 | Duration: 2 min\n",
      "Epoch 13 | Iter 1000 | Loss: 1.5377004146575928 | Duration: 2 min\n",
      "Epoch 13 | Iter 2000 | Loss: 1.5795657634735107 | Duration: 2 min\n",
      "Epoch 13 | Iter 3000 | Loss: 1.4792506694793701 | Duration: 2 min\n",
      "Epoch 13 | Iter 4000 | Loss: 1.6130441427230835 | Duration: 2 min\n",
      "Epoch 13 | Iter 5000 | Loss: 1.5584803819656372 | Duration: 2 min\n",
      "Epoch 13 | Iter 6000 | Loss: 1.508685827255249 | Duration: 2 min\n",
      "Epoch 13 | Iter 7000 | Loss: 1.5451359748840332 | Duration: 2 min\n",
      "Epoch 13 | Iter 8000 | Loss: 1.5872069597244263 | Duration: 2 min\n",
      "Epoch 13 | Iter 9000 | Loss: 1.5780848264694214 | Duration: 2 min\n",
      "Epoch 13 | Iter 10000 | Loss: 1.539061188697815 | Duration: 2 min\n",
      "Epoch 13 | Iter 11000 | Loss: 1.6184520721435547 | Duration: 2 min\n",
      "Epoch 13 | Iter 12000 | Loss: 1.5290298461914062 | Duration: 2 min\n",
      "Epoch 13 | Iter 13000 | Loss: 1.5957642793655396 | Duration: 2 min\n",
      "Epoch 13 | Iter 14000 | Loss: 1.604030966758728 | Duration: 2 min\n",
      "Epoch 13 | Iter 15000 | Loss: 1.5431042909622192 | Duration: 2 min\n",
      "Epoch 14 | Iter 1000 | Loss: 1.5131112337112427 | Duration: 2 min\n",
      "Epoch 14 | Iter 2000 | Loss: 1.443799614906311 | Duration: 2 min\n",
      "Epoch 14 | Iter 3000 | Loss: 1.4554437398910522 | Duration: 2 min\n",
      "Epoch 14 | Iter 4000 | Loss: 1.611169457435608 | Duration: 2 min\n",
      "Epoch 14 | Iter 5000 | Loss: 1.4879751205444336 | Duration: 2 min\n",
      "Epoch 14 | Iter 6000 | Loss: 1.4685324430465698 | Duration: 2 min\n",
      "Epoch 14 | Iter 7000 | Loss: 1.4672478437423706 | Duration: 2 min\n",
      "Epoch 14 | Iter 8000 | Loss: 1.584290862083435 | Duration: 2 min\n",
      "Epoch 14 | Iter 9000 | Loss: 1.5346581935882568 | Duration: 2 min\n",
      "Epoch 14 | Iter 10000 | Loss: 1.534359335899353 | Duration: 2 min\n",
      "Epoch 14 | Iter 11000 | Loss: 1.5377262830734253 | Duration: 2 min\n",
      "Epoch 14 | Iter 12000 | Loss: 1.560291051864624 | Duration: 2 min\n",
      "Epoch 14 | Iter 13000 | Loss: 1.5358234643936157 | Duration: 2 min\n",
      "Epoch 14 | Iter 14000 | Loss: 1.5459976196289062 | Duration: 2 min\n",
      "Epoch 14 | Iter 15000 | Loss: 1.6009960174560547 | Duration: 2 min\n",
      "Epoch 15 | Iter 1000 | Loss: 1.504174828529358 | Duration: 2 min\n",
      "Epoch 15 | Iter 2000 | Loss: 1.4727030992507935 | Duration: 2 min\n",
      "Epoch 15 | Iter 3000 | Loss: 1.4580622911453247 | Duration: 2 min\n",
      "Epoch 15 | Iter 4000 | Loss: 1.4761662483215332 | Duration: 2 min\n",
      "Epoch 15 | Iter 5000 | Loss: 1.4726917743682861 | Duration: 2 min\n",
      "Epoch 15 | Iter 6000 | Loss: 1.4916117191314697 | Duration: 2 min\n",
      "Epoch 15 | Iter 7000 | Loss: 1.4755529165267944 | Duration: 2 min\n",
      "Epoch 15 | Iter 8000 | Loss: 1.5240941047668457 | Duration: 2 min\n",
      "Epoch 15 | Iter 9000 | Loss: 1.5191460847854614 | Duration: 2 min\n",
      "Epoch 15 | Iter 10000 | Loss: 1.4901785850524902 | Duration: 2 min\n",
      "Epoch 15 | Iter 11000 | Loss: 1.4249516725540161 | Duration: 2 min\n",
      "Epoch 15 | Iter 12000 | Loss: 1.450974941253662 | Duration: 2 min\n",
      "Epoch 15 | Iter 13000 | Loss: 1.5251548290252686 | Duration: 2 min\n",
      "Epoch 15 | Iter 14000 | Loss: 1.6006344556808472 | Duration: 2 min\n",
      "Epoch 15 | Iter 15000 | Loss: 1.5181052684783936 | Duration: 2 min\n",
      "Epoch 16 | Iter 1000 | Loss: 1.4387612342834473 | Duration: 2 min\n",
      "Epoch 16 | Iter 2000 | Loss: 1.404799461364746 | Duration: 2 min\n",
      "Epoch 16 | Iter 3000 | Loss: 1.4242457151412964 | Duration: 2 min\n",
      "Epoch 16 | Iter 4000 | Loss: 1.4279813766479492 | Duration: 2 min\n",
      "Epoch 16 | Iter 5000 | Loss: 1.3612382411956787 | Duration: 2 min\n",
      "Epoch 16 | Iter 6000 | Loss: 1.4595732688903809 | Duration: 2 min\n",
      "Epoch 16 | Iter 7000 | Loss: 1.4992413520812988 | Duration: 2 min\n",
      "Epoch 16 | Iter 8000 | Loss: 1.5561211109161377 | Duration: 2 min\n",
      "Epoch 16 | Iter 9000 | Loss: 1.5546019077301025 | Duration: 2 min\n",
      "Epoch 16 | Iter 10000 | Loss: 1.4266399145126343 | Duration: 2 min\n",
      "Epoch 16 | Iter 11000 | Loss: 1.533847451210022 | Duration: 2 min\n",
      "Epoch 16 | Iter 12000 | Loss: 1.4293192625045776 | Duration: 2 min\n",
      "Epoch 16 | Iter 13000 | Loss: 1.5005643367767334 | Duration: 2 min\n",
      "Epoch 16 | Iter 14000 | Loss: 1.4683414697647095 | Duration: 2 min\n",
      "Epoch 16 | Iter 15000 | Loss: 1.4512311220169067 | Duration: 2 min\n",
      "Epoch 17 | Iter 1000 | Loss: 1.3787357807159424 | Duration: 2 min\n",
      "Epoch 17 | Iter 2000 | Loss: 1.4396302700042725 | Duration: 2 min\n",
      "Epoch 17 | Iter 3000 | Loss: 1.365866780281067 | Duration: 2 min\n",
      "Epoch 17 | Iter 4000 | Loss: 1.4337331056594849 | Duration: 2 min\n",
      "Epoch 17 | Iter 5000 | Loss: 1.4316624402999878 | Duration: 2 min\n",
      "Epoch 17 | Iter 6000 | Loss: 1.4697015285491943 | Duration: 2 min\n",
      "Epoch 17 | Iter 7000 | Loss: 1.4231195449829102 | Duration: 2 min\n",
      "Epoch 17 | Iter 8000 | Loss: 1.4584968090057373 | Duration: 2 min\n",
      "Epoch 17 | Iter 9000 | Loss: 1.4176491498947144 | Duration: 2 min\n",
      "Epoch 17 | Iter 10000 | Loss: 1.4353200197219849 | Duration: 2 min\n",
      "Epoch 17 | Iter 11000 | Loss: 1.4794589281082153 | Duration: 2 min\n",
      "Epoch 17 | Iter 12000 | Loss: 1.4491500854492188 | Duration: 2 min\n",
      "Epoch 17 | Iter 13000 | Loss: 1.440874695777893 | Duration: 2 min\n",
      "Epoch 17 | Iter 14000 | Loss: 1.4341877698898315 | Duration: 2 min\n",
      "Epoch 17 | Iter 15000 | Loss: 1.4137500524520874 | Duration: 2 min\n",
      "Epoch 18 | Iter 1000 | Loss: 1.3309524059295654 | Duration: 2 min\n",
      "Epoch 18 | Iter 2000 | Loss: 1.321213960647583 | Duration: 2 min\n",
      "Epoch 18 | Iter 3000 | Loss: 1.3550363779067993 | Duration: 2 min\n",
      "Epoch 18 | Iter 4000 | Loss: 1.4188838005065918 | Duration: 2 min\n",
      "Epoch 18 | Iter 5000 | Loss: 1.3577232360839844 | Duration: 2 min\n",
      "Epoch 18 | Iter 6000 | Loss: 1.3936456441879272 | Duration: 2 min\n",
      "Epoch 18 | Iter 7000 | Loss: 1.418054461479187 | Duration: 2 min\n",
      "Epoch 18 | Iter 8000 | Loss: 1.4065039157867432 | Duration: 2 min\n",
      "Epoch 18 | Iter 9000 | Loss: 1.3537672758102417 | Duration: 2 min\n",
      "Epoch 18 | Iter 10000 | Loss: 1.4431040287017822 | Duration: 2 min\n",
      "Epoch 18 | Iter 11000 | Loss: 1.4439845085144043 | Duration: 2 min\n",
      "Epoch 18 | Iter 12000 | Loss: 1.4219354391098022 | Duration: 2 min\n",
      "Epoch 18 | Iter 13000 | Loss: 1.4301416873931885 | Duration: 2 min\n",
      "Epoch 18 | Iter 14000 | Loss: 1.3473201990127563 | Duration: 2 min\n",
      "Epoch 18 | Iter 15000 | Loss: 1.4287042617797852 | Duration: 2 min\n",
      "Epoch 19 | Iter 1000 | Loss: 1.3614015579223633 | Duration: 2 min\n",
      "Epoch 19 | Iter 2000 | Loss: 1.3057366609573364 | Duration: 2 min\n",
      "Epoch 19 | Iter 3000 | Loss: 1.3677239418029785 | Duration: 2 min\n",
      "Epoch 19 | Iter 4000 | Loss: 1.353831171989441 | Duration: 2 min\n",
      "Epoch 19 | Iter 5000 | Loss: 1.4291948080062866 | Duration: 2 min\n",
      "Epoch 19 | Iter 6000 | Loss: 1.333719253540039 | Duration: 2 min\n",
      "Epoch 19 | Iter 7000 | Loss: 1.3297314643859863 | Duration: 2 min\n",
      "Epoch 19 | Iter 8000 | Loss: 1.3614592552185059 | Duration: 2 min\n",
      "Epoch 19 | Iter 9000 | Loss: 1.342431664466858 | Duration: 2 min\n",
      "Epoch 19 | Iter 10000 | Loss: 1.383184552192688 | Duration: 2 min\n",
      "Epoch 19 | Iter 11000 | Loss: 1.3031524419784546 | Duration: 2 min\n",
      "Epoch 19 | Iter 12000 | Loss: 1.3234182596206665 | Duration: 2 min\n",
      "Epoch 19 | Iter 13000 | Loss: 1.352922797203064 | Duration: 2 min\n",
      "Epoch 19 | Iter 14000 | Loss: 1.403564453125 | Duration: 2 min\n",
      "Epoch 19 | Iter 15000 | Loss: 1.3920084238052368 | Duration: 2 min\n",
      "Epoch 20 | Iter 1000 | Loss: 1.2296142578125 | Duration: 2 min\n",
      "Epoch 20 | Iter 2000 | Loss: 1.2290399074554443 | Duration: 2 min\n",
      "Epoch 20 | Iter 3000 | Loss: 1.331169605255127 | Duration: 2 min\n",
      "Epoch 20 | Iter 4000 | Loss: 1.327864646911621 | Duration: 2 min\n",
      "Epoch 20 | Iter 5000 | Loss: 1.271936058998108 | Duration: 2 min\n",
      "Epoch 20 | Iter 6000 | Loss: 1.308687686920166 | Duration: 2 min\n",
      "Epoch 20 | Iter 7000 | Loss: 1.3524081707000732 | Duration: 2 min\n",
      "Epoch 20 | Iter 8000 | Loss: 1.2684704065322876 | Duration: 2 min\n",
      "Epoch 20 | Iter 9000 | Loss: 1.2828924655914307 | Duration: 2 min\n",
      "Epoch 20 | Iter 10000 | Loss: 1.3382352590560913 | Duration: 2 min\n",
      "Epoch 20 | Iter 11000 | Loss: 1.3268225193023682 | Duration: 2 min\n",
      "Epoch 20 | Iter 12000 | Loss: 1.35780668258667 | Duration: 2 min\n",
      "Epoch 20 | Iter 13000 | Loss: 1.2995070219039917 | Duration: 2 min\n",
      "Epoch 20 | Iter 14000 | Loss: 1.3529095649719238 | Duration: 2 min\n",
      "Epoch 20 | Iter 15000 | Loss: 1.355448603630066 | Duration: 2 min\n",
      "Epoch 21 | Iter 1000 | Loss: 1.254817008972168 | Duration: 2 min\n",
      "Epoch 21 | Iter 2000 | Loss: 1.2730790376663208 | Duration: 2 min\n",
      "Epoch 21 | Iter 3000 | Loss: 1.2514126300811768 | Duration: 2 min\n",
      "Epoch 21 | Iter 4000 | Loss: 1.2279504537582397 | Duration: 2 min\n",
      "Epoch 21 | Iter 5000 | Loss: 1.2468738555908203 | Duration: 2 min\n",
      "Epoch 21 | Iter 6000 | Loss: 1.306685209274292 | Duration: 2 min\n",
      "Epoch 21 | Iter 7000 | Loss: 1.2412692308425903 | Duration: 2 min\n",
      "Epoch 21 | Iter 8000 | Loss: 1.2469409704208374 | Duration: 2 min\n",
      "Epoch 21 | Iter 9000 | Loss: 1.3099247217178345 | Duration: 2 min\n",
      "Epoch 21 | Iter 10000 | Loss: 1.32541823387146 | Duration: 2 min\n",
      "Epoch 21 | Iter 11000 | Loss: 1.271470546722412 | Duration: 2 min\n",
      "Epoch 21 | Iter 12000 | Loss: 1.2786189317703247 | Duration: 2 min\n",
      "Epoch 21 | Iter 13000 | Loss: 1.2847073078155518 | Duration: 2 min\n",
      "Epoch 21 | Iter 14000 | Loss: 1.2732564210891724 | Duration: 2 min\n",
      "Epoch 21 | Iter 15000 | Loss: 1.3102755546569824 | Duration: 2 min\n",
      "Epoch 22 | Iter 1000 | Loss: 1.2270582914352417 | Duration: 2 min\n",
      "Epoch 22 | Iter 2000 | Loss: 1.1893266439437866 | Duration: 2 min\n",
      "Epoch 22 | Iter 3000 | Loss: 1.211667776107788 | Duration: 2 min\n",
      "Epoch 22 | Iter 4000 | Loss: 1.2102463245391846 | Duration: 2 min\n",
      "Epoch 22 | Iter 5000 | Loss: 1.2510300874710083 | Duration: 2 min\n",
      "Epoch 22 | Iter 6000 | Loss: 1.1919814348220825 | Duration: 2 min\n",
      "Epoch 22 | Iter 7000 | Loss: 1.322823166847229 | Duration: 2 min\n",
      "Epoch 22 | Iter 8000 | Loss: 1.2215802669525146 | Duration: 2 min\n",
      "Epoch 22 | Iter 9000 | Loss: 1.1980403661727905 | Duration: 2 min\n",
      "Epoch 22 | Iter 10000 | Loss: 1.2570239305496216 | Duration: 2 min\n",
      "Epoch 22 | Iter 11000 | Loss: 1.2129439115524292 | Duration: 2 min\n",
      "Epoch 22 | Iter 12000 | Loss: 1.2272326946258545 | Duration: 2 min\n",
      "Epoch 22 | Iter 13000 | Loss: 1.2405245304107666 | Duration: 2 min\n",
      "Epoch 22 | Iter 14000 | Loss: 1.236126184463501 | Duration: 2 min\n",
      "Epoch 22 | Iter 15000 | Loss: 1.2320239543914795 | Duration: 2 min\n",
      "Epoch 23 | Iter 1000 | Loss: 1.1760934591293335 | Duration: 2 min\n",
      "Epoch 23 | Iter 2000 | Loss: 1.2335418462753296 | Duration: 2 min\n",
      "Epoch 23 | Iter 3000 | Loss: 1.2011538743972778 | Duration: 2 min\n",
      "Epoch 23 | Iter 4000 | Loss: 1.144391655921936 | Duration: 2 min\n",
      "Epoch 23 | Iter 5000 | Loss: 1.2233270406723022 | Duration: 2 min\n",
      "Epoch 23 | Iter 6000 | Loss: 1.1760436296463013 | Duration: 2 min\n",
      "Epoch 23 | Iter 7000 | Loss: 1.1306499242782593 | Duration: 2 min\n",
      "Epoch 23 | Iter 8000 | Loss: 1.191906452178955 | Duration: 2 min\n",
      "Epoch 23 | Iter 9000 | Loss: 1.216436505317688 | Duration: 2 min\n",
      "Epoch 23 | Iter 10000 | Loss: 1.2342078685760498 | Duration: 2 min\n",
      "Epoch 23 | Iter 11000 | Loss: 1.2020704746246338 | Duration: 2 min\n",
      "Epoch 23 | Iter 12000 | Loss: 1.1712478399276733 | Duration: 2 min\n",
      "Epoch 23 | Iter 13000 | Loss: 1.2010916471481323 | Duration: 2 min\n",
      "Epoch 23 | Iter 14000 | Loss: 1.1420059204101562 | Duration: 2 min\n",
      "Epoch 23 | Iter 15000 | Loss: 1.1732531785964966 | Duration: 2 min\n",
      "Epoch 24 | Iter 1000 | Loss: 1.0956480503082275 | Duration: 2 min\n",
      "Epoch 24 | Iter 2000 | Loss: 1.1592165231704712 | Duration: 2 min\n",
      "Epoch 24 | Iter 3000 | Loss: 1.0949904918670654 | Duration: 2 min\n",
      "Epoch 24 | Iter 4000 | Loss: 1.1232043504714966 | Duration: 2 min\n",
      "Epoch 24 | Iter 5000 | Loss: 1.113261342048645 | Duration: 2 min\n",
      "Epoch 24 | Iter 6000 | Loss: 1.1055368185043335 | Duration: 2 min\n",
      "Epoch 24 | Iter 7000 | Loss: 1.1757068634033203 | Duration: 2 min\n",
      "Epoch 24 | Iter 8000 | Loss: 1.146700143814087 | Duration: 2 min\n",
      "Epoch 24 | Iter 9000 | Loss: 1.179608941078186 | Duration: 2 min\n",
      "Epoch 24 | Iter 10000 | Loss: 1.1628334522247314 | Duration: 2 min\n",
      "Epoch 24 | Iter 11000 | Loss: 1.1770094633102417 | Duration: 2 min\n",
      "Epoch 24 | Iter 12000 | Loss: 1.1100412607192993 | Duration: 2 min\n",
      "Epoch 24 | Iter 13000 | Loss: 1.1508562564849854 | Duration: 2 min\n",
      "Epoch 24 | Iter 14000 | Loss: 1.145313024520874 | Duration: 2 min\n",
      "Epoch 24 | Iter 15000 | Loss: 1.1791367530822754 | Duration: 2 min\n",
      "Epoch 25 | Iter 1000 | Loss: 1.0541355609893799 | Duration: 2 min\n",
      "Epoch 25 | Iter 2000 | Loss: 1.0915722846984863 | Duration: 2 min\n",
      "Epoch 25 | Iter 3000 | Loss: 1.0396965742111206 | Duration: 2 min\n",
      "Epoch 25 | Iter 4000 | Loss: 1.0904574394226074 | Duration: 2 min\n",
      "Epoch 25 | Iter 5000 | Loss: 1.0602474212646484 | Duration: 2 min\n",
      "Epoch 25 | Iter 6000 | Loss: 1.0658231973648071 | Duration: 2 min\n",
      "Epoch 25 | Iter 7000 | Loss: 1.0829893350601196 | Duration: 2 min\n",
      "Epoch 25 | Iter 8000 | Loss: 1.1317126750946045 | Duration: 2 min\n",
      "Epoch 25 | Iter 9000 | Loss: 1.0611985921859741 | Duration: 2 min\n",
      "Epoch 25 | Iter 10000 | Loss: 1.1401278972625732 | Duration: 2 min\n",
      "Epoch 25 | Iter 11000 | Loss: 1.1140055656433105 | Duration: 2 min\n",
      "Epoch 25 | Iter 12000 | Loss: 1.101370930671692 | Duration: 2 min\n",
      "Epoch 25 | Iter 13000 | Loss: 1.137420654296875 | Duration: 2 min\n",
      "Epoch 25 | Iter 14000 | Loss: 1.1441285610198975 | Duration: 2 min\n",
      "Epoch 25 | Iter 15000 | Loss: 1.1186152696609497 | Duration: 2 min\n",
      "Epoch 26 | Iter 1000 | Loss: 1.0642638206481934 | Duration: 2 min\n",
      "Epoch 26 | Iter 2000 | Loss: 1.0409839153289795 | Duration: 2 min\n",
      "Epoch 26 | Iter 3000 | Loss: 1.0254155397415161 | Duration: 2 min\n",
      "Epoch 26 | Iter 4000 | Loss: 1.0673891305923462 | Duration: 2 min\n",
      "Epoch 26 | Iter 5000 | Loss: 1.0445995330810547 | Duration: 2 min\n",
      "Epoch 26 | Iter 6000 | Loss: 1.0237772464752197 | Duration: 2 min\n",
      "Epoch 26 | Iter 7000 | Loss: 1.023595929145813 | Duration: 2 min\n",
      "Epoch 26 | Iter 8000 | Loss: 1.0968412160873413 | Duration: 2 min\n",
      "Epoch 26 | Iter 9000 | Loss: 1.0418775081634521 | Duration: 2 min\n",
      "Epoch 26 | Iter 10000 | Loss: 1.0679683685302734 | Duration: 2 min\n",
      "Epoch 26 | Iter 11000 | Loss: 1.0646703243255615 | Duration: 2 min\n",
      "Epoch 26 | Iter 12000 | Loss: 1.0502912998199463 | Duration: 2 min\n",
      "Epoch 26 | Iter 13000 | Loss: 1.064829707145691 | Duration: 2 min\n",
      "Epoch 26 | Iter 14000 | Loss: 1.0225130319595337 | Duration: 2 min\n",
      "Epoch 26 | Iter 15000 | Loss: 1.041366696357727 | Duration: 2 min\n",
      "Epoch 27 | Iter 1000 | Loss: 1.0050636529922485 | Duration: 2 min\n",
      "Epoch 27 | Iter 2000 | Loss: 0.995598316192627 | Duration: 2 min\n",
      "Epoch 27 | Iter 3000 | Loss: 1.01137113571167 | Duration: 2 min\n",
      "Epoch 27 | Iter 4000 | Loss: 1.0014501810073853 | Duration: 2 min\n",
      "Epoch 27 | Iter 5000 | Loss: 1.0133163928985596 | Duration: 2 min\n",
      "Epoch 27 | Iter 6000 | Loss: 0.9805695414543152 | Duration: 2 min\n",
      "Epoch 27 | Iter 7000 | Loss: 1.0312390327453613 | Duration: 2 min\n",
      "Epoch 27 | Iter 8000 | Loss: 0.9946881532669067 | Duration: 2 min\n",
      "Epoch 27 | Iter 9000 | Loss: 1.0746164321899414 | Duration: 2 min\n",
      "Epoch 27 | Iter 10000 | Loss: 0.9909948110580444 | Duration: 2 min\n",
      "Epoch 27 | Iter 11000 | Loss: 0.9818142056465149 | Duration: 2 min\n",
      "Epoch 27 | Iter 12000 | Loss: 0.9955395460128784 | Duration: 2 min\n",
      "Epoch 27 | Iter 13000 | Loss: 1.0201637744903564 | Duration: 2 min\n",
      "Epoch 27 | Iter 14000 | Loss: 1.0624773502349854 | Duration: 2 min\n",
      "Epoch 27 | Iter 15000 | Loss: 0.9719690084457397 | Duration: 2 min\n",
      "Epoch 28 | Iter 1000 | Loss: 0.9502847194671631 | Duration: 2 min\n",
      "Epoch 28 | Iter 2000 | Loss: 0.9520228505134583 | Duration: 2 min\n",
      "Epoch 28 | Iter 3000 | Loss: 0.9224473237991333 | Duration: 2 min\n",
      "Epoch 28 | Iter 4000 | Loss: 1.0158003568649292 | Duration: 2 min\n",
      "Epoch 28 | Iter 5000 | Loss: 0.9489420056343079 | Duration: 2 min\n",
      "Epoch 28 | Iter 6000 | Loss: 0.9573402404785156 | Duration: 2 min\n",
      "Epoch 28 | Iter 7000 | Loss: 0.9248013496398926 | Duration: 2 min\n",
      "Epoch 28 | Iter 8000 | Loss: 0.9540294408798218 | Duration: 2 min\n",
      "Epoch 28 | Iter 9000 | Loss: 0.9693175554275513 | Duration: 2 min\n",
      "Epoch 28 | Iter 10000 | Loss: 0.939818263053894 | Duration: 2 min\n",
      "Epoch 28 | Iter 11000 | Loss: 0.9375427961349487 | Duration: 2 min\n",
      "Epoch 28 | Iter 12000 | Loss: 0.9679238200187683 | Duration: 2 min\n",
      "Epoch 28 | Iter 13000 | Loss: 0.9748626351356506 | Duration: 2 min\n",
      "Epoch 28 | Iter 14000 | Loss: 1.0102601051330566 | Duration: 2 min\n",
      "Epoch 28 | Iter 15000 | Loss: 0.9689323902130127 | Duration: 2 min\n",
      "Epoch 29 | Iter 1000 | Loss: 0.8992491364479065 | Duration: 2 min\n",
      "Epoch 29 | Iter 2000 | Loss: 0.8959712386131287 | Duration: 2 min\n",
      "Epoch 29 | Iter 3000 | Loss: 0.9259543418884277 | Duration: 2 min\n",
      "Epoch 29 | Iter 4000 | Loss: 0.884850025177002 | Duration: 2 min\n",
      "Epoch 29 | Iter 5000 | Loss: 0.866003692150116 | Duration: 2 min\n",
      "Epoch 29 | Iter 6000 | Loss: 0.9017031192779541 | Duration: 2 min\n",
      "Epoch 29 | Iter 7000 | Loss: 0.8996375203132629 | Duration: 2 min\n",
      "Epoch 29 | Iter 8000 | Loss: 0.9115296006202698 | Duration: 2 min\n",
      "Epoch 29 | Iter 9000 | Loss: 0.9037826061248779 | Duration: 2 min\n",
      "Epoch 29 | Iter 10000 | Loss: 0.8940694332122803 | Duration: 2 min\n",
      "Epoch 29 | Iter 11000 | Loss: 0.9543945789337158 | Duration: 2 min\n",
      "Epoch 29 | Iter 12000 | Loss: 0.9399959444999695 | Duration: 2 min\n",
      "Epoch 29 | Iter 13000 | Loss: 0.9374607801437378 | Duration: 2 min\n",
      "Epoch 29 | Iter 14000 | Loss: 0.9625925421714783 | Duration: 2 min\n",
      "Epoch 29 | Iter 15000 | Loss: 0.908486008644104 | Duration: 2 min\n",
      "Epoch 30 | Iter 1000 | Loss: 0.838154673576355 | Duration: 2 min\n",
      "Epoch 30 | Iter 2000 | Loss: 0.871071457862854 | Duration: 2 min\n",
      "Epoch 30 | Iter 3000 | Loss: 0.8175997138023376 | Duration: 2 min\n",
      "Epoch 30 | Iter 4000 | Loss: 0.8705075979232788 | Duration: 2 min\n",
      "Epoch 30 | Iter 5000 | Loss: 0.856986939907074 | Duration: 2 min\n",
      "Epoch 30 | Iter 6000 | Loss: 0.8879573345184326 | Duration: 2 min\n",
      "Epoch 30 | Iter 7000 | Loss: 0.8682869076728821 | Duration: 2 min\n",
      "Epoch 30 | Iter 8000 | Loss: 0.8909895420074463 | Duration: 2 min\n",
      "Epoch 30 | Iter 9000 | Loss: 0.8427251577377319 | Duration: 2 min\n",
      "Epoch 30 | Iter 10000 | Loss: 0.8709497451782227 | Duration: 2 min\n",
      "Epoch 30 | Iter 11000 | Loss: 0.8470019698143005 | Duration: 2 min\n",
      "Epoch 30 | Iter 12000 | Loss: 0.8738217353820801 | Duration: 2 min\n",
      "Epoch 30 | Iter 13000 | Loss: 0.8776323795318604 | Duration: 2 min\n",
      "Epoch 30 | Iter 14000 | Loss: 0.9088729619979858 | Duration: 2 min\n",
      "Epoch 30 | Iter 15000 | Loss: 0.8927399516105652 | Duration: 2 min\n",
      "Epoch 31 | Iter 1000 | Loss: 0.8023346662521362 | Duration: 2 min\n",
      "Epoch 31 | Iter 2000 | Loss: 0.8115601539611816 | Duration: 2 min\n",
      "Epoch 31 | Iter 3000 | Loss: 0.8426925539970398 | Duration: 2 min\n",
      "Epoch 31 | Iter 4000 | Loss: 0.8184512853622437 | Duration: 2 min\n",
      "Epoch 31 | Iter 5000 | Loss: 0.8056974411010742 | Duration: 2 min\n",
      "Epoch 31 | Iter 6000 | Loss: 0.806197464466095 | Duration: 2 min\n",
      "Epoch 31 | Iter 7000 | Loss: 0.822139322757721 | Duration: 2 min\n",
      "Epoch 31 | Iter 8000 | Loss: 0.861720621585846 | Duration: 2 min\n",
      "Epoch 31 | Iter 9000 | Loss: 0.8203867077827454 | Duration: 2 min\n",
      "Epoch 31 | Iter 10000 | Loss: 0.8000795245170593 | Duration: 2 min\n",
      "Epoch 31 | Iter 11000 | Loss: 0.8571836948394775 | Duration: 2 min\n",
      "Epoch 31 | Iter 12000 | Loss: 0.8659601211547852 | Duration: 2 min\n",
      "Epoch 31 | Iter 13000 | Loss: 0.8655547499656677 | Duration: 2 min\n",
      "Epoch 31 | Iter 14000 | Loss: 0.8213419914245605 | Duration: 2 min\n",
      "Epoch 31 | Iter 15000 | Loss: 0.8267946243286133 | Duration: 2 min\n",
      "Epoch 32 | Iter 1000 | Loss: 0.7995479702949524 | Duration: 2 min\n",
      "Epoch 32 | Iter 2000 | Loss: 0.7785113453865051 | Duration: 2 min\n",
      "Epoch 32 | Iter 3000 | Loss: 0.7714792490005493 | Duration: 2 min\n",
      "Epoch 32 | Iter 4000 | Loss: 0.8216376900672913 | Duration: 2 min\n",
      "Epoch 32 | Iter 5000 | Loss: 0.7815929651260376 | Duration: 2 min\n",
      "Epoch 32 | Iter 6000 | Loss: 0.8094655275344849 | Duration: 2 min\n",
      "Epoch 32 | Iter 7000 | Loss: 0.7983552813529968 | Duration: 2 min\n",
      "Epoch 32 | Iter 8000 | Loss: 0.7978289723396301 | Duration: 2 min\n",
      "Epoch 32 | Iter 9000 | Loss: 0.7691651582717896 | Duration: 2 min\n",
      "Epoch 32 | Iter 10000 | Loss: 0.8116022944450378 | Duration: 2 min\n",
      "Epoch 32 | Iter 11000 | Loss: 0.7529798150062561 | Duration: 2 min\n",
      "Epoch 32 | Iter 12000 | Loss: 0.8038644194602966 | Duration: 2 min\n",
      "Epoch 32 | Iter 13000 | Loss: 0.7573896646499634 | Duration: 2 min\n",
      "Epoch 32 | Iter 14000 | Loss: 0.7754867672920227 | Duration: 2 min\n",
      "Epoch 32 | Iter 15000 | Loss: 0.7953669428825378 | Duration: 2 min\n",
      "Epoch 33 | Iter 1000 | Loss: 0.7625582218170166 | Duration: 2 min\n",
      "Epoch 33 | Iter 2000 | Loss: 0.7373585104942322 | Duration: 2 min\n",
      "Epoch 33 | Iter 3000 | Loss: 0.7701292037963867 | Duration: 2 min\n",
      "Epoch 33 | Iter 4000 | Loss: 0.7657663822174072 | Duration: 2 min\n",
      "Epoch 33 | Iter 5000 | Loss: 0.7343028783798218 | Duration: 2 min\n",
      "Epoch 33 | Iter 6000 | Loss: 0.7354533076286316 | Duration: 2 min\n",
      "Epoch 33 | Iter 7000 | Loss: 0.7612031102180481 | Duration: 2 min\n",
      "Epoch 33 | Iter 8000 | Loss: 0.7363759875297546 | Duration: 2 min\n",
      "Epoch 33 | Iter 9000 | Loss: 0.7617073655128479 | Duration: 2 min\n",
      "Epoch 33 | Iter 10000 | Loss: 0.7373311519622803 | Duration: 2 min\n",
      "Epoch 33 | Iter 11000 | Loss: 0.7433754205703735 | Duration: 2 min\n",
      "Epoch 33 | Iter 12000 | Loss: 0.7673508524894714 | Duration: 2 min\n",
      "Epoch 33 | Iter 13000 | Loss: 0.742316722869873 | Duration: 2 min\n",
      "Epoch 33 | Iter 14000 | Loss: 0.8024318814277649 | Duration: 2 min\n",
      "Epoch 33 | Iter 15000 | Loss: 0.7427652478218079 | Duration: 2 min\n",
      "Epoch 34 | Iter 1000 | Loss: 0.7220871448516846 | Duration: 2 min\n",
      "Epoch 34 | Iter 2000 | Loss: 0.7487993836402893 | Duration: 2 min\n",
      "Epoch 34 | Iter 3000 | Loss: 0.7164623141288757 | Duration: 2 min\n",
      "Epoch 34 | Iter 4000 | Loss: 0.7112959027290344 | Duration: 2 min\n",
      "Epoch 34 | Iter 5000 | Loss: 0.6878435015678406 | Duration: 2 min\n",
      "Epoch 34 | Iter 6000 | Loss: 0.7205133438110352 | Duration: 2 min\n",
      "Epoch 34 | Iter 7000 | Loss: 0.6973798274993896 | Duration: 2 min\n",
      "Epoch 34 | Iter 8000 | Loss: 0.7504103183746338 | Duration: 2 min\n",
      "Epoch 34 | Iter 9000 | Loss: 0.750569224357605 | Duration: 2 min\n",
      "Epoch 34 | Iter 10000 | Loss: 0.7321527600288391 | Duration: 2 min\n",
      "Epoch 34 | Iter 11000 | Loss: 0.736267626285553 | Duration: 2 min\n",
      "Epoch 34 | Iter 12000 | Loss: 0.7136227488517761 | Duration: 2 min\n",
      "Epoch 34 | Iter 13000 | Loss: 0.731060802936554 | Duration: 2 min\n",
      "Epoch 34 | Iter 14000 | Loss: 0.7503666281700134 | Duration: 2 min\n",
      "Epoch 34 | Iter 15000 | Loss: 0.7110724449157715 | Duration: 2 min\n",
      "Epoch 35 | Iter 1000 | Loss: 0.6749196648597717 | Duration: 2 min\n",
      "Epoch 35 | Iter 2000 | Loss: 0.6752503514289856 | Duration: 2 min\n",
      "Epoch 35 | Iter 3000 | Loss: 0.6884618401527405 | Duration: 2 min\n",
      "Epoch 35 | Iter 4000 | Loss: 0.7183342576026917 | Duration: 2 min\n",
      "Epoch 35 | Iter 5000 | Loss: 0.7037478089332581 | Duration: 2 min\n",
      "Epoch 35 | Iter 6000 | Loss: 0.6720355749130249 | Duration: 2 min\n",
      "Epoch 35 | Iter 7000 | Loss: 0.7147350311279297 | Duration: 2 min\n",
      "Epoch 35 | Iter 8000 | Loss: 0.7088584303855896 | Duration: 2 min\n",
      "Epoch 35 | Iter 9000 | Loss: 0.6982030272483826 | Duration: 2 min\n",
      "Epoch 35 | Iter 10000 | Loss: 0.722282886505127 | Duration: 2 min\n",
      "Epoch 35 | Iter 11000 | Loss: 0.6898432374000549 | Duration: 2 min\n",
      "Epoch 35 | Iter 12000 | Loss: 0.7089425325393677 | Duration: 2 min\n",
      "Epoch 35 | Iter 13000 | Loss: 0.6840212941169739 | Duration: 2 min\n",
      "Epoch 35 | Iter 14000 | Loss: 0.7350095510482788 | Duration: 2 min\n",
      "Epoch 35 | Iter 15000 | Loss: 0.6828572750091553 | Duration: 2 min\n",
      "Epoch 36 | Iter 1000 | Loss: 0.6829392910003662 | Duration: 2 min\n",
      "Epoch 36 | Iter 2000 | Loss: 0.6762723922729492 | Duration: 2 min\n",
      "Epoch 36 | Iter 3000 | Loss: 0.686759352684021 | Duration: 2 min\n",
      "Epoch 36 | Iter 4000 | Loss: 0.6914463639259338 | Duration: 2 min\n",
      "Epoch 36 | Iter 5000 | Loss: 0.6673434376716614 | Duration: 2 min\n",
      "Epoch 36 | Iter 6000 | Loss: 0.6797258853912354 | Duration: 2 min\n",
      "Epoch 36 | Iter 7000 | Loss: 0.6822434663772583 | Duration: 2 min\n",
      "Epoch 36 | Iter 8000 | Loss: 0.6910918951034546 | Duration: 2 min\n",
      "Epoch 36 | Iter 9000 | Loss: 0.6821387410163879 | Duration: 2 min\n",
      "Epoch 36 | Iter 10000 | Loss: 0.6673306822776794 | Duration: 2 min\n",
      "Epoch 36 | Iter 11000 | Loss: 0.6271132230758667 | Duration: 2 min\n",
      "Epoch 36 | Iter 12000 | Loss: 0.6850111484527588 | Duration: 2 min\n",
      "Epoch 36 | Iter 13000 | Loss: 0.6760889887809753 | Duration: 2 min\n",
      "Epoch 36 | Iter 14000 | Loss: 0.713463544845581 | Duration: 2 min\n",
      "Epoch 36 | Iter 15000 | Loss: 0.6839855313301086 | Duration: 2 min\n",
      "Epoch 37 | Iter 1000 | Loss: 0.6938725113868713 | Duration: 2 min\n",
      "Epoch 37 | Iter 2000 | Loss: 0.6648092865943909 | Duration: 2 min\n",
      "Epoch 37 | Iter 3000 | Loss: 0.6755695939064026 | Duration: 2 min\n",
      "Epoch 37 | Iter 4000 | Loss: 0.6585188508033752 | Duration: 2 min\n",
      "Epoch 37 | Iter 5000 | Loss: 0.6509597897529602 | Duration: 2 min\n",
      "Epoch 37 | Iter 6000 | Loss: 0.6675674319267273 | Duration: 2 min\n",
      "Epoch 37 | Iter 7000 | Loss: 0.6597113013267517 | Duration: 2 min\n",
      "Epoch 37 | Iter 8000 | Loss: 0.6425707936286926 | Duration: 2 min\n",
      "Epoch 37 | Iter 9000 | Loss: 0.6445323824882507 | Duration: 2 min\n",
      "Epoch 37 | Iter 10000 | Loss: 0.6839221119880676 | Duration: 1 min\n",
      "Epoch 37 | Iter 11000 | Loss: 0.6579836010932922 | Duration: 1 min\n",
      "Epoch 37 | Iter 12000 | Loss: 0.6496434211730957 | Duration: 1 min\n",
      "Epoch 37 | Iter 13000 | Loss: 0.6567709445953369 | Duration: 1 min\n",
      "Epoch 37 | Iter 14000 | Loss: 0.6782925724983215 | Duration: 1 min\n",
      "Epoch 37 | Iter 15000 | Loss: 0.6777832508087158 | Duration: 1 min\n",
      "Epoch 38 | Iter 1000 | Loss: 0.6394672989845276 | Duration: 1 min\n",
      "Epoch 38 | Iter 2000 | Loss: 0.6566715836524963 | Duration: 1 min\n",
      "Epoch 38 | Iter 3000 | Loss: 0.6761277914047241 | Duration: 1 min\n",
      "Epoch 38 | Iter 4000 | Loss: 0.64240562915802 | Duration: 1 min\n",
      "Epoch 38 | Iter 5000 | Loss: 0.6520205140113831 | Duration: 1 min\n",
      "Epoch 38 | Iter 6000 | Loss: 0.6670657396316528 | Duration: 1 min\n",
      "Epoch 38 | Iter 7000 | Loss: 0.6623552441596985 | Duration: 1 min\n",
      "Epoch 38 | Iter 8000 | Loss: 0.6646586060523987 | Duration: 2 min\n",
      "Epoch 38 | Iter 9000 | Loss: 0.6507129669189453 | Duration: 2 min\n",
      "Epoch 38 | Iter 10000 | Loss: 0.6486709117889404 | Duration: 2 min\n",
      "Epoch 38 | Iter 11000 | Loss: 0.6473848819732666 | Duration: 2 min\n",
      "Epoch 38 | Iter 12000 | Loss: 0.6454969644546509 | Duration: 2 min\n",
      "Epoch 38 | Iter 13000 | Loss: 0.6639000177383423 | Duration: 2 min\n",
      "Epoch 38 | Iter 14000 | Loss: 0.642789900302887 | Duration: 2 min\n",
      "Epoch 38 | Iter 15000 | Loss: 0.6529359817504883 | Duration: 2 min\n",
      "Epoch 39 | Iter 1000 | Loss: 0.6232960820198059 | Duration: 2 min\n",
      "Epoch 39 | Iter 2000 | Loss: 0.6414464712142944 | Duration: 2 min\n",
      "Epoch 39 | Iter 3000 | Loss: 0.641267716884613 | Duration: 2 min\n",
      "Epoch 39 | Iter 4000 | Loss: 0.6635811924934387 | Duration: 2 min\n",
      "Epoch 39 | Iter 5000 | Loss: 0.6228684782981873 | Duration: 2 min\n",
      "Epoch 39 | Iter 6000 | Loss: 0.676344633102417 | Duration: 2 min\n",
      "Epoch 39 | Iter 7000 | Loss: 0.6693559885025024 | Duration: 2 min\n",
      "Epoch 39 | Iter 8000 | Loss: 0.6806005835533142 | Duration: 2 min\n",
      "Epoch 39 | Iter 9000 | Loss: 0.6284372806549072 | Duration: 2 min\n",
      "Epoch 39 | Iter 10000 | Loss: 0.6374115347862244 | Duration: 2 min\n",
      "Epoch 39 | Iter 11000 | Loss: 0.6502894163131714 | Duration: 2 min\n",
      "Epoch 39 | Iter 12000 | Loss: 0.6265091896057129 | Duration: 2 min\n",
      "Epoch 39 | Iter 13000 | Loss: 0.631427526473999 | Duration: 2 min\n",
      "Epoch 39 | Iter 14000 | Loss: 0.6676846146583557 | Duration: 2 min\n",
      "Epoch 39 | Iter 15000 | Loss: 0.640388548374176 | Duration: 2 min\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "total_epoch = 40\n",
    "\n",
    "len_data = 15000\n",
    "term = 1000\n",
    "\n",
    "loss_sum = 0\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(params = model.parameters(),lr = 0.001, momentum = 0.9, weight_decay=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,total_epoch,eta_min=0.00001)\n",
    "\n",
    "try:\n",
    "  check_point = torch.load(\"runs/Faster_RCNN/Check_point.pth\") \n",
    "  start_epoch = check_point['epoch']\n",
    "  start_idx = check_point['iter']\n",
    "  model.load_state_dict(check_point['state_dict'])\n",
    "  optimizer.load_state_dict(check_point['optimizer'])\n",
    "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,total_epoch,eta_min=0.00001,last_epoch = start_epoch)\n",
    "  scheduler.load_state_dict(check_point['scheduler'])\n",
    "\n",
    "  if start_idx == len_data: \n",
    "    start_idx = 0\n",
    "    start_epoch = start_epoch + 1\n",
    "\n",
    "except:\n",
    "  print(\"check point load error!\")\n",
    "  start_epoch = 0\n",
    "  start_idx = 0\n",
    "\n",
    "print(\"start_epoch = {} , start_idx = {}\".format(start_epoch,start_idx))\n",
    "\n",
    "print(\"Training Start\")\n",
    "model.train()\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(start_epoch,total_epoch):\n",
    "  \n",
    "  writer.add_scalar('Learning Rate',scheduler.get_last_lr()[0], epoch)\n",
    "\n",
    "  dataset = Pascal_Voc(xml_list[:len_data],len_data - start_idx)\n",
    "  dataloader = DataLoader(dataset,shuffle=True)\n",
    "\n",
    "  for i, (image,targets)in enumerate(dataloader,start_idx):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    targets[0]['boxes'].squeeze_(0)\n",
    "    targets[0]['labels'].squeeze_(0)\n",
    "    \n",
    "    loss = model(image.to(device),targets)\n",
    "    total_loss = Total_Loss(loss)\n",
    "    loss_sum += total_loss\n",
    "\n",
    "    if (i+1) % term == 0:\n",
    "      end = time.time()\n",
    "      print(\"Epoch {} | Iter {} | Loss: {} | Duration: {} min\".format(epoch,(i+1),(loss_sum/term).item(),int((end-start)/60)))\n",
    "      writer.add_scalar('Training Loss',loss_sum / term, epoch * len_data + i)\n",
    "      \n",
    "      state = {\n",
    "        'epoch': epoch,\n",
    "        'iter' : i+1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "        'scheduler': scheduler.state_dict()\n",
    "      }\n",
    "      torch.save(state,\"runs/Faster_RCNN/Check_point.pth\")\n",
    "     \n",
    "      loss_sum = 0\n",
    "      start = time.time()\n",
    "    \n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  start_idx = 0\n",
    "  scheduler.step() \n",
    "\n",
    "  state = {\n",
    "      'epoch': epoch,\n",
    "      'iter' : i+1,\n",
    "      'state_dict': model.state_dict(),\n",
    "      'optimizer' : optimizer.state_dict(),\n",
    "      'scheduler': scheduler.state_dict()\n",
    "    }\n",
    "  torch.save(state, \"runs/Faster_RCNN/Check_point.pth\")\n",
    "\n",
    "  if (epoch+1) % 10 == 0: \n",
    "    torch.save(model.state_dict(),\"runs/Faster_RCNN/Epoch{}.pth\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9, device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0]['boxes'].squeeze_(0)\n",
    "targets[0]['labels'].squeeze_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dfbd672e28bbed90d5d5d40f9aaa2ef1070e421b4c18d3a50b2720b9a48f0aa6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
