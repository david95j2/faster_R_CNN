{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = models.mobilenet_v2(pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 400, 400]             864\n",
      "       BatchNorm2d-2         [-1, 32, 400, 400]              64\n",
      "             ReLU6-3         [-1, 32, 400, 400]               0\n",
      "            Conv2d-4         [-1, 32, 400, 400]             288\n",
      "       BatchNorm2d-5         [-1, 32, 400, 400]              64\n",
      "             ReLU6-6         [-1, 32, 400, 400]               0\n",
      "            Conv2d-7         [-1, 16, 400, 400]             512\n",
      "       BatchNorm2d-8         [-1, 16, 400, 400]              32\n",
      "  InvertedResidual-9         [-1, 16, 400, 400]               0\n",
      "           Conv2d-10         [-1, 96, 400, 400]           1,536\n",
      "      BatchNorm2d-11         [-1, 96, 400, 400]             192\n",
      "            ReLU6-12         [-1, 96, 400, 400]               0\n",
      "           Conv2d-13         [-1, 96, 200, 200]             864\n",
      "      BatchNorm2d-14         [-1, 96, 200, 200]             192\n",
      "            ReLU6-15         [-1, 96, 200, 200]               0\n",
      "           Conv2d-16         [-1, 24, 200, 200]           2,304\n",
      "      BatchNorm2d-17         [-1, 24, 200, 200]              48\n",
      " InvertedResidual-18         [-1, 24, 200, 200]               0\n",
      "           Conv2d-19        [-1, 144, 200, 200]           3,456\n",
      "      BatchNorm2d-20        [-1, 144, 200, 200]             288\n",
      "            ReLU6-21        [-1, 144, 200, 200]               0\n",
      "           Conv2d-22        [-1, 144, 200, 200]           1,296\n",
      "      BatchNorm2d-23        [-1, 144, 200, 200]             288\n",
      "            ReLU6-24        [-1, 144, 200, 200]               0\n",
      "           Conv2d-25         [-1, 24, 200, 200]           3,456\n",
      "      BatchNorm2d-26         [-1, 24, 200, 200]              48\n",
      " InvertedResidual-27         [-1, 24, 200, 200]               0\n",
      "           Conv2d-28        [-1, 144, 200, 200]           3,456\n",
      "      BatchNorm2d-29        [-1, 144, 200, 200]             288\n",
      "            ReLU6-30        [-1, 144, 200, 200]               0\n",
      "           Conv2d-31        [-1, 144, 100, 100]           1,296\n",
      "      BatchNorm2d-32        [-1, 144, 100, 100]             288\n",
      "            ReLU6-33        [-1, 144, 100, 100]               0\n",
      "           Conv2d-34         [-1, 32, 100, 100]           4,608\n",
      "      BatchNorm2d-35         [-1, 32, 100, 100]              64\n",
      " InvertedResidual-36         [-1, 32, 100, 100]               0\n",
      "           Conv2d-37        [-1, 192, 100, 100]           6,144\n",
      "      BatchNorm2d-38        [-1, 192, 100, 100]             384\n",
      "            ReLU6-39        [-1, 192, 100, 100]               0\n",
      "           Conv2d-40        [-1, 192, 100, 100]           1,728\n",
      "      BatchNorm2d-41        [-1, 192, 100, 100]             384\n",
      "            ReLU6-42        [-1, 192, 100, 100]               0\n",
      "           Conv2d-43         [-1, 32, 100, 100]           6,144\n",
      "      BatchNorm2d-44         [-1, 32, 100, 100]              64\n",
      " InvertedResidual-45         [-1, 32, 100, 100]               0\n",
      "           Conv2d-46        [-1, 192, 100, 100]           6,144\n",
      "      BatchNorm2d-47        [-1, 192, 100, 100]             384\n",
      "            ReLU6-48        [-1, 192, 100, 100]               0\n",
      "           Conv2d-49        [-1, 192, 100, 100]           1,728\n",
      "      BatchNorm2d-50        [-1, 192, 100, 100]             384\n",
      "            ReLU6-51        [-1, 192, 100, 100]               0\n",
      "           Conv2d-52         [-1, 32, 100, 100]           6,144\n",
      "      BatchNorm2d-53         [-1, 32, 100, 100]              64\n",
      " InvertedResidual-54         [-1, 32, 100, 100]               0\n",
      "           Conv2d-55        [-1, 192, 100, 100]           6,144\n",
      "      BatchNorm2d-56        [-1, 192, 100, 100]             384\n",
      "            ReLU6-57        [-1, 192, 100, 100]               0\n",
      "           Conv2d-58          [-1, 192, 50, 50]           1,728\n",
      "      BatchNorm2d-59          [-1, 192, 50, 50]             384\n",
      "            ReLU6-60          [-1, 192, 50, 50]               0\n",
      "           Conv2d-61           [-1, 64, 50, 50]          12,288\n",
      "      BatchNorm2d-62           [-1, 64, 50, 50]             128\n",
      " InvertedResidual-63           [-1, 64, 50, 50]               0\n",
      "           Conv2d-64          [-1, 384, 50, 50]          24,576\n",
      "      BatchNorm2d-65          [-1, 384, 50, 50]             768\n",
      "            ReLU6-66          [-1, 384, 50, 50]               0\n",
      "           Conv2d-67          [-1, 384, 50, 50]           3,456\n",
      "      BatchNorm2d-68          [-1, 384, 50, 50]             768\n",
      "            ReLU6-69          [-1, 384, 50, 50]               0\n",
      "           Conv2d-70           [-1, 64, 50, 50]          24,576\n",
      "      BatchNorm2d-71           [-1, 64, 50, 50]             128\n",
      " InvertedResidual-72           [-1, 64, 50, 50]               0\n",
      "           Conv2d-73          [-1, 384, 50, 50]          24,576\n",
      "      BatchNorm2d-74          [-1, 384, 50, 50]             768\n",
      "            ReLU6-75          [-1, 384, 50, 50]               0\n",
      "           Conv2d-76          [-1, 384, 50, 50]           3,456\n",
      "      BatchNorm2d-77          [-1, 384, 50, 50]             768\n",
      "            ReLU6-78          [-1, 384, 50, 50]               0\n",
      "           Conv2d-79           [-1, 64, 50, 50]          24,576\n",
      "      BatchNorm2d-80           [-1, 64, 50, 50]             128\n",
      " InvertedResidual-81           [-1, 64, 50, 50]               0\n",
      "           Conv2d-82          [-1, 384, 50, 50]          24,576\n",
      "      BatchNorm2d-83          [-1, 384, 50, 50]             768\n",
      "            ReLU6-84          [-1, 384, 50, 50]               0\n",
      "           Conv2d-85          [-1, 384, 50, 50]           3,456\n",
      "      BatchNorm2d-86          [-1, 384, 50, 50]             768\n",
      "            ReLU6-87          [-1, 384, 50, 50]               0\n",
      "           Conv2d-88           [-1, 64, 50, 50]          24,576\n",
      "      BatchNorm2d-89           [-1, 64, 50, 50]             128\n",
      " InvertedResidual-90           [-1, 64, 50, 50]               0\n",
      "           Conv2d-91          [-1, 384, 50, 50]          24,576\n",
      "      BatchNorm2d-92          [-1, 384, 50, 50]             768\n",
      "            ReLU6-93          [-1, 384, 50, 50]               0\n",
      "           Conv2d-94          [-1, 384, 50, 50]           3,456\n",
      "      BatchNorm2d-95          [-1, 384, 50, 50]             768\n",
      "            ReLU6-96          [-1, 384, 50, 50]               0\n",
      "           Conv2d-97           [-1, 96, 50, 50]          36,864\n",
      "      BatchNorm2d-98           [-1, 96, 50, 50]             192\n",
      " InvertedResidual-99           [-1, 96, 50, 50]               0\n",
      "          Conv2d-100          [-1, 576, 50, 50]          55,296\n",
      "     BatchNorm2d-101          [-1, 576, 50, 50]           1,152\n",
      "           ReLU6-102          [-1, 576, 50, 50]               0\n",
      "          Conv2d-103          [-1, 576, 50, 50]           5,184\n",
      "     BatchNorm2d-104          [-1, 576, 50, 50]           1,152\n",
      "           ReLU6-105          [-1, 576, 50, 50]               0\n",
      "          Conv2d-106           [-1, 96, 50, 50]          55,296\n",
      "     BatchNorm2d-107           [-1, 96, 50, 50]             192\n",
      "InvertedResidual-108           [-1, 96, 50, 50]               0\n",
      "          Conv2d-109          [-1, 576, 50, 50]          55,296\n",
      "     BatchNorm2d-110          [-1, 576, 50, 50]           1,152\n",
      "           ReLU6-111          [-1, 576, 50, 50]               0\n",
      "          Conv2d-112          [-1, 576, 50, 50]           5,184\n",
      "     BatchNorm2d-113          [-1, 576, 50, 50]           1,152\n",
      "           ReLU6-114          [-1, 576, 50, 50]               0\n",
      "          Conv2d-115           [-1, 96, 50, 50]          55,296\n",
      "     BatchNorm2d-116           [-1, 96, 50, 50]             192\n",
      "InvertedResidual-117           [-1, 96, 50, 50]               0\n",
      "          Conv2d-118          [-1, 576, 50, 50]          55,296\n",
      "     BatchNorm2d-119          [-1, 576, 50, 50]           1,152\n",
      "           ReLU6-120          [-1, 576, 50, 50]               0\n",
      "          Conv2d-121          [-1, 576, 25, 25]           5,184\n",
      "     BatchNorm2d-122          [-1, 576, 25, 25]           1,152\n",
      "           ReLU6-123          [-1, 576, 25, 25]               0\n",
      "          Conv2d-124          [-1, 160, 25, 25]          92,160\n",
      "     BatchNorm2d-125          [-1, 160, 25, 25]             320\n",
      "InvertedResidual-126          [-1, 160, 25, 25]               0\n",
      "          Conv2d-127          [-1, 960, 25, 25]         153,600\n",
      "     BatchNorm2d-128          [-1, 960, 25, 25]           1,920\n",
      "           ReLU6-129          [-1, 960, 25, 25]               0\n",
      "          Conv2d-130          [-1, 960, 25, 25]           8,640\n",
      "     BatchNorm2d-131          [-1, 960, 25, 25]           1,920\n",
      "           ReLU6-132          [-1, 960, 25, 25]               0\n",
      "          Conv2d-133          [-1, 160, 25, 25]         153,600\n",
      "     BatchNorm2d-134          [-1, 160, 25, 25]             320\n",
      "InvertedResidual-135          [-1, 160, 25, 25]               0\n",
      "          Conv2d-136          [-1, 960, 25, 25]         153,600\n",
      "     BatchNorm2d-137          [-1, 960, 25, 25]           1,920\n",
      "           ReLU6-138          [-1, 960, 25, 25]               0\n",
      "          Conv2d-139          [-1, 960, 25, 25]           8,640\n",
      "     BatchNorm2d-140          [-1, 960, 25, 25]           1,920\n",
      "           ReLU6-141          [-1, 960, 25, 25]               0\n",
      "          Conv2d-142          [-1, 160, 25, 25]         153,600\n",
      "     BatchNorm2d-143          [-1, 160, 25, 25]             320\n",
      "InvertedResidual-144          [-1, 160, 25, 25]               0\n",
      "          Conv2d-145          [-1, 960, 25, 25]         153,600\n",
      "     BatchNorm2d-146          [-1, 960, 25, 25]           1,920\n",
      "           ReLU6-147          [-1, 960, 25, 25]               0\n",
      "          Conv2d-148          [-1, 960, 25, 25]           8,640\n",
      "     BatchNorm2d-149          [-1, 960, 25, 25]           1,920\n",
      "           ReLU6-150          [-1, 960, 25, 25]               0\n",
      "          Conv2d-151          [-1, 320, 25, 25]         307,200\n",
      "     BatchNorm2d-152          [-1, 320, 25, 25]             640\n",
      "InvertedResidual-153          [-1, 320, 25, 25]               0\n",
      "          Conv2d-154         [-1, 1280, 25, 25]         409,600\n",
      "     BatchNorm2d-155         [-1, 1280, 25, 25]           2,560\n",
      "           ReLU6-156         [-1, 1280, 25, 25]               0\n",
      "         Dropout-157                 [-1, 1280]               0\n",
      "          Linear-158                 [-1, 1000]       1,281,000\n",
      "================================================================\n",
      "Total params: 3,504,872\n",
      "Trainable params: 3,504,872\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 7.32\n",
      "Forward/backward pass size (MB): 1949.63\n",
      "Params size (MB): 13.37\n",
      "Estimated Total Size (MB): 1970.33\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(backbone, input_size=(3,800,800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "[ConvNormActivation(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      "), InvertedResidual(\n",
      "  (conv): Sequential(\n",
      "    (0): ConvNormActivation(\n",
      "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), InvertedResidual(\n",
      "  (conv): Sequential(\n",
      "    (0): ConvNormActivation(\n",
      "      (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): ConvNormActivation(\n",
      "      (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), InvertedResidual(\n",
      "  (conv): Sequential(\n",
      "    (0): ConvNormActivation(\n",
      "      (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): ConvNormActivation(\n",
      "      (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "      (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), InvertedResidual(\n",
      "  (conv): Sequential(\n",
      "    (0): ConvNormActivation(\n",
      "      (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): ConvNormActivation(\n",
      "      (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "      (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), InvertedResidual(\n",
      "  (conv): Sequential(\n",
      "    (0): ConvNormActivation(\n",
      "      (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): ConvNormActivation(\n",
      "      (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), InvertedResidual(\n",
      "  (conv): Sequential(\n",
      "    (0): ConvNormActivation(\n",
      "      (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): ConvNormActivation(\n",
      "      (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), InvertedResidual(\n",
      "  (conv): Sequential(\n",
      "    (0): ConvNormActivation(\n",
      "      (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): ConvNormActivation(\n",
      "      (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), InvertedResidual(\n",
      "  (conv): Sequential(\n",
      "    (0): ConvNormActivation(\n",
      "      (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): ConvNormActivation(\n",
      "      (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), InvertedResidual(\n",
      "  (conv): Sequential(\n",
      "    (0): ConvNormActivation(\n",
      "      (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): ConvNormActivation(\n",
      "      (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), InvertedResidual(\n",
      "  (conv): Sequential(\n",
      "    (0): ConvNormActivation(\n",
      "      (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): ConvNormActivation(\n",
      "      (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), InvertedResidual(\n",
      "  (conv): Sequential(\n",
      "    (0): ConvNormActivation(\n",
      "      (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): ConvNormActivation(\n",
      "      (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), InvertedResidual(\n",
      "  (conv): Sequential(\n",
      "    (0): ConvNormActivation(\n",
      "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): ConvNormActivation(\n",
      "      (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "      (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), InvertedResidual(\n",
      "  (conv): Sequential(\n",
      "    (0): ConvNormActivation(\n",
      "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): ConvNormActivation(\n",
      "      (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "      (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), InvertedResidual(\n",
      "  (conv): Sequential(\n",
      "    (0): ConvNormActivation(\n",
      "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): ConvNormActivation(\n",
      "      (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "      (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), InvertedResidual(\n",
      "  (conv): Sequential(\n",
      "    (0): ConvNormActivation(\n",
      "      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): ConvNormActivation(\n",
      "      (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "      (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), InvertedResidual(\n",
      "  (conv): Sequential(\n",
      "    (0): ConvNormActivation(\n",
      "      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): ConvNormActivation(\n",
      "      (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "      (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), InvertedResidual(\n",
      "  (conv): Sequential(\n",
      "    (0): ConvNormActivation(\n",
      "      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): ConvNormActivation(\n",
      "      (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "      (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), ConvNormActivation(\n",
      "  (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "features = list(backbone.features)\n",
    "print(len(features))\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 800, 800])\n",
      "19\n",
      "torch.Size([1, 1280, 25, 25])\n",
      "1280\n"
     ]
    }
   ],
   "source": [
    "# only collect layers with output feature map size (W, H) < 50\n",
    "\n",
    "dummy_img = torch.zeros((1, 3, 800, 800)).float()  # test image array\n",
    "print(dummy_img.shape)\n",
    "\n",
    "req_features = []\n",
    "output = dummy_img.clone().to(device)\n",
    "\n",
    "for feature in features:\n",
    "    output = feature(output)\n",
    "    # print(output.size()) # => torch.Size([batch_size, channel, width, height])\n",
    "    # if output.size()[2] < 800//16:  # 800/16=50\n",
    "    #     break\n",
    "    req_features.append(feature)\n",
    "    out_channels = output.size()\n",
    "\n",
    "print(len(req_features))\n",
    "# print(req_features)\n",
    "print(out_channels)\n",
    "print(out_channels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert this list into a Seqeuntial module\n",
    "\n",
    "faster_rcnn_feature_extractor = nn.Sequential(*req_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the results of the input image pass through the feature extractor\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "imgTensor = transform(img).to(device)\n",
    "imgTensor = imgTensor.unsqueeze(0)\n",
    "output_map = faster_rcnn_feature_extractor(imgTensor)\n",
    "\n",
    "print(output_map.size())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dfbd672e28bbed90d5d5d40f9aaa2ef1070e421b4c18d3a50b2720b9a48f0aa6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
