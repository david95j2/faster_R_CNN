{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torchvision import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET\n",
    "from typing import Any, Callable, Dict, Optional, Tuple, List\n",
    "import collections\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace=True)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace=True)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace=True)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace=True)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace=True)\n",
      "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU(inplace=True)\n",
      "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace=True)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace=True)\n",
      "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): ReLU(inplace=True)\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU(inplace=True)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vgg16 = models.vgg16(pretrained=True).features[:-1].to(device)\n",
    "\n",
    "print(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 244, 244]           1,792\n",
      "              ReLU-2         [-1, 64, 244, 244]               0\n",
      "            Conv2d-3         [-1, 64, 244, 244]          36,928\n",
      "              ReLU-4         [-1, 64, 244, 244]               0\n",
      "         MaxPool2d-5         [-1, 64, 122, 122]               0\n",
      "            Conv2d-6        [-1, 128, 122, 122]          73,856\n",
      "              ReLU-7        [-1, 128, 122, 122]               0\n",
      "            Conv2d-8        [-1, 128, 122, 122]         147,584\n",
      "              ReLU-9        [-1, 128, 122, 122]               0\n",
      "        MaxPool2d-10          [-1, 128, 61, 61]               0\n",
      "           Conv2d-11          [-1, 256, 61, 61]         295,168\n",
      "             ReLU-12          [-1, 256, 61, 61]               0\n",
      "           Conv2d-13          [-1, 256, 61, 61]         590,080\n",
      "             ReLU-14          [-1, 256, 61, 61]               0\n",
      "           Conv2d-15          [-1, 256, 61, 61]         590,080\n",
      "             ReLU-16          [-1, 256, 61, 61]               0\n",
      "        MaxPool2d-17          [-1, 256, 30, 30]               0\n",
      "           Conv2d-18          [-1, 512, 30, 30]       1,180,160\n",
      "             ReLU-19          [-1, 512, 30, 30]               0\n",
      "           Conv2d-20          [-1, 512, 30, 30]       2,359,808\n",
      "             ReLU-21          [-1, 512, 30, 30]               0\n",
      "           Conv2d-22          [-1, 512, 30, 30]       2,359,808\n",
      "             ReLU-23          [-1, 512, 30, 30]               0\n",
      "        MaxPool2d-24          [-1, 512, 15, 15]               0\n",
      "           Conv2d-25          [-1, 512, 15, 15]       2,359,808\n",
      "             ReLU-26          [-1, 512, 15, 15]               0\n",
      "           Conv2d-27          [-1, 512, 15, 15]       2,359,808\n",
      "             ReLU-28          [-1, 512, 15, 15]               0\n",
      "           Conv2d-29          [-1, 512, 15, 15]       2,359,808\n",
      "             ReLU-30          [-1, 512, 15, 15]               0\n",
      "================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.68\n",
      "Forward/backward pass size (MB): 257.93\n",
      "Params size (MB): 56.13\n",
      "Estimated Total Size (MB): 314.75\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(vgg16, input_size=(3,244,244), device=device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 3, 3])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the filters of the first CNN layer\n",
    "# display sample images\n",
    "def show(img, y=None, color=True):\n",
    "    npimg = img.numpy()\n",
    "    npimg_tr = np.transpose(npimg, (1, 2, 0))\n",
    "    plt.imshow(npimg_tr)\n",
    "\n",
    "    if y is not None:\n",
    "        plt.title('labels: ' + str(y))\n",
    "\n",
    "for w in vgg16.parameters():\n",
    "    w = w.data.cpu()\n",
    "    print(w.shape)\n",
    "    break\n",
    "\n",
    "# normalize weights\n",
    "min_w = torch.min(w)\n",
    "w1 = (-1/(2 * min_w)) * w + 0.5\n",
    "\n",
    "# make grid to display it\n",
    "grid_size = len(w1)\n",
    "x_grid = [w1[i] for i in range(grid_size)]\n",
    "x_grid = utils.make_grid(x_grid, nrow=8, padding=1)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "show(x_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2data = '../../../../../../data/test/Annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"wasp nest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as Et\n",
    "\n",
    "def xml_parser(xml_path):\n",
    "    xml_path = xml_path\n",
    "    xml = open(xml_path, \"r\")\n",
    "    tree = Et.parse(xml)\n",
    "    root = tree.getroot()\n",
    "    size = root.find(\"size\")\n",
    "    file_name = root.find(\"filename\").text\n",
    "    object_name = []\n",
    "    bbox = []\n",
    "    objects = root.findall(\"object\")\n",
    "    for _object in objects:\n",
    "      name = _object.find(\"name\").text\n",
    "      object_name.append(name)\n",
    "      bndbox = _object.find(\"bndbox\")\n",
    "      one_bbox = []\n",
    "      xmin = bndbox.find(\"xmin\").text\n",
    "      one_bbox.append(int(float(xmin)))\n",
    "      ymin = bndbox.find(\"ymin\").text\n",
    "      one_bbox.append(int(float(ymin)))\n",
    "      xmax = bndbox.find(\"xmax\").text\n",
    "      one_bbox.append(int(float(xmax)))\n",
    "      ymax = bndbox.find(\"ymax\").text\n",
    "      one_bbox.append(int(float(ymax)))\n",
    "      bbox.append(one_bbox)\n",
    "    return file_name, object_name, bbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeBox(voc_im,bbox,objects):\n",
    "    image = voc_im.copy()\n",
    "    for i in range(len(objects)):\n",
    "        cv2.rectangle(image,(int(bbox[i][0]),int(bbox[i][1])),(int(bbox[i][2]),int(bbox[i][3])),color = (0,255,0),thickness = 1)\n",
    "        cv2.putText(image, objects[i], (int(bbox[i][0]), int(bbox[i][1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2) # 크기, 색, 굵기\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_list = os.listdir(\"../../../../../../data/test/Annotations\")\n",
    "xml_list.sort()\n",
    "\n",
    "label_set = set()\n",
    "\n",
    "for i in range(len(xml_list)):\n",
    "  xml_path = \"../../../../../../data/test/Annotations/\"+str(xml_list[i])\n",
    "  file_name, object_name, bbox = xml_parser(xml_path)\n",
    "  for name in object_name:\n",
    "    label_set.add(name)\n",
    "\n",
    "label_set = sorted(list(label_set))\n",
    "\n",
    "label_dic = {}\n",
    "for i, key in enumerate(label_set):\n",
    "  label_dic[key] = (i+1)\n",
    "print(label_dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Pascal_Voc(Dataset):\n",
    "    \n",
    "  def __init__(self,xml_list,len_data):\n",
    "\n",
    "    self.xml_list = xml_list\n",
    "    self.len_data = len_data\n",
    "    self.to_tensor = transforms.ToTensor()\n",
    "    self.flip = iaa.Fliplr(0.5)\n",
    "    self.resize = iaa.Resize({\"shorter-side\": 600, \"longer-side\": \"keep-aspect-ratio\"})\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.len_data\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "\n",
    "    xml_path = \"../../../../../../data/test/Annotations/\"+str(xml_list[idx])\n",
    "\n",
    "    file_name, object_name, bbox = xml_parser(xml_path)\n",
    "    image_path = \"../../../../../../data/test/JPEGImages/\"+str(file_name)\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = np.array(image)\n",
    "\n",
    "    image, bbox = self.flip(image = image, bounding_boxes = np.array([bbox]))\n",
    "    image, bbox = self.resize(image = image,bounding_boxes = bbox)\n",
    "    bbox = bbox.squeeze(0).tolist()\n",
    "    image = self.to_tensor(image)\n",
    "\n",
    "    targets = []\n",
    "    d = {}\n",
    "    d['boxes'] = torch.tensor(bbox,device=device)\n",
    "    d['labels'] = torch.tensor([label_dic[x] for x in object_name],dtype=torch.int64,device = device)\n",
    "    targets.append(d)\n",
    "\n",
    "    return image, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch에서 제공하는 VOC dataset을 상속받아, custom dataset을 생성합니다.\n",
    "class myVOCDetection(Dataset):\n",
    "    def __getitem__(self, index):\n",
    "        img = np.array(Image.open(self.images[index]).convert('RGB'))\n",
    "        target = self.parse_voc_xml(\n",
    "            ET.parse(self.annotations[index]).getroot())  # xml파일 분석하여 dict으로 받아오기\n",
    "\n",
    "        targets = []  # 바운딩 박스 좌표\n",
    "        labels = []  # 바운딩 박스 클래스\n",
    "\n",
    "        # 바운딩 박스 정보 받아오기\n",
    "        for t in target['annotation']['object']:\n",
    "            label = np.zeros(5)\n",
    "            label[:] = t['bndbox']['xmin'], t['bndbox']['ymin'], t['bndbox']['xmax'], t['bndbox']['ymax'], classes.index(\n",
    "                t['name'])\n",
    "\n",
    "            targets.append(list(label[:4]))  # 바운딩 박스 좌표\n",
    "            labels.append(label[4])         # 바운딩 박스 클래스\n",
    "\n",
    "        if self.transforms:\n",
    "            augmentations = self.transforms(image=img, bboxes=targets)\n",
    "            img = augmentations['image']\n",
    "            targets = augmentations['bboxes']\n",
    "\n",
    "        return img, targets, labels\n",
    "\n",
    "    # xml 파일을 dictionary로 반환\n",
    "    def parse_voc_xml(self, node: ET.Element) -> Dict[str, Any]:\n",
    "        voc_dict: Dict[str, Any] = {}\n",
    "        children = list(node)\n",
    "        if children:\n",
    "            def_dic: Dict[str, Any] = collections.defaultdict(list)\n",
    "            for dc in map(self.parse_voc_xml, children):\n",
    "                for ind, v in dc.items():\n",
    "                    def_dic[ind].append(v)\n",
    "            if node.tag == \"annotation\":\n",
    "                def_dic[\"object\"] = [def_dic[\"object\"]]\n",
    "            voc_dict = {node.tag: {ind: v[0] if len(\n",
    "                v) == 1 else v for ind, v in def_dic.items()}}\n",
    "        if node.text:\n",
    "            text = node.text.strip()\n",
    "            if not children:\n",
    "                voc_dict[node.tag] = text\n",
    "        return voc_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = torchvision.datasets.ImageFolder(root=\"baby_data/train\", transform=transforms.ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 이미지 확인\n",
    "img, target, label = train_ds[2]\n",
    "colors = np.random.randint(0, 255, size=(80, 3), dtype='uint8')  # 바운딩 박스 색상\n",
    "\n",
    "# 시각화 함수\n",
    "\n",
    "\n",
    "def show(img, targets, labels, classes=classes):\n",
    "    img = to_pil_image(img)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    targets = np.array(targets)\n",
    "    W, H = img.size\n",
    "\n",
    "    for tg, label in zip(targets, labels):\n",
    "        id_ = int(label)  # class\n",
    "        bbox = tg[:4]    # [x1, y1, x2, y2]\n",
    "\n",
    "        color = [int(c) for c in colors[id_]]\n",
    "        name = classes[id_]\n",
    "\n",
    "        draw.rectangle(((bbox[0], bbox[1]), (bbox[2], bbox[3])),\n",
    "                       outline=tuple(color), width=3)\n",
    "        draw.text((bbox[0], bbox[1]), name, fill=(255, 255, 255, 0))\n",
    "    plt.imshow(np.array(img))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "show(img, target, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dfbd672e28bbed90d5d5d40f9aaa2ef1070e421b4c18d3a50b2720b9a48f0aa6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
